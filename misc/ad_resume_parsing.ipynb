{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"496pt\" height=\"764pt\"\n",
       " viewBox=\"0.00 0.00 496.00 764.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 760)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-760 492,-760 492,4 -4,4\"/>\n",
       "<!-- cv_text -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>cv_text</title>\n",
       "<text text-anchor=\"middle\" x=\"455\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text</text>\n",
       "</g>\n",
       "<!-- _mk_parser -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>_mk_parser</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"401.5,-540 320.5,-540 320.5,-504 401.5,-504 401.5,-540\"/>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">_mk_parser</text>\n",
       "</g>\n",
       "<!-- cv_text&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>cv_text&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M431.76,-575.7C419.81,-566.8 405.08,-555.82 392.15,-546.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"394.08,-543.27 383.97,-540.1 389.9,-548.88 394.08,-543.27\"/>\n",
       "</g>\n",
       "<!-- translate_content -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>translate_content</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"289.5,-108 180.5,-108 180.5,-72 289.5,-72 289.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"235\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">translate_content</text>\n",
       "</g>\n",
       "<!-- cv_text&#45;&gt;translate_content -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>cv_text&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M455,-575.95C455,-549.29 455,-496.11 455,-451 455,-451 455,-451 455,-233 455,-192.25 461.53,-173.09 433,-144 398.39,-108.72 343.07,-96.12 299.69,-91.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.76,-88.47 289.5,-91.14 299.18,-95.45 299.76,-88.47\"/>\n",
       "</g>\n",
       "<!-- cv_name -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>cv_name</title>\n",
       "<text text-anchor=\"middle\" x=\"455\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_name</text>\n",
       "</g>\n",
       "<!-- cv_text_ -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>cv_text_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"486.5,-684 423.5,-684 423.5,-648 486.5,-648 486.5,-684\"/>\n",
       "<text text-anchor=\"middle\" x=\"455\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text_</text>\n",
       "</g>\n",
       "<!-- cv_name&#45;&gt;cv_text_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>cv_name&#45;&gt;cv_text_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M455,-719.7C455,-711.98 455,-702.71 455,-694.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"458.5,-694.1 455,-684.1 451.5,-694.1 458.5,-694.1\"/>\n",
       "</g>\n",
       "<!-- cv_text_&#45;&gt;cv_text -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>cv_text_&#45;&gt;cv_text</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M455,-647.7C455,-639.98 455,-630.71 455,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"458.5,-622.1 455,-612.1 451.5,-622.1 458.5,-622.1\"/>\n",
       "</g>\n",
       "<!-- raw_dict_content -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>raw_dict_content</title>\n",
       "<text text-anchor=\"middle\" x=\"361\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">raw_dict_content</text>\n",
       "</g>\n",
       "<!-- has_content_labelling -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>has_content_labelling</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"417.5,-396 282.5,-396 282.5,-360 417.5,-360 417.5,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"350\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">has_content_labelling</text>\n",
       "</g>\n",
       "<!-- raw_dict_content&#45;&gt;has_content_labelling -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>raw_dict_content&#45;&gt;has_content_labelling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.28,-431.7C357.07,-423.98 355.61,-414.71 354.26,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.7,-405.44 352.69,-396.1 350.78,-406.53 357.7,-405.44\"/>\n",
       "</g>\n",
       "<!-- chunk_overlap -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>chunk_overlap</title>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunk_overlap=</text>\n",
       "</g>\n",
       "<!-- chunk_overlap&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>chunk_overlap&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M210.43,-575.97C240.84,-565.27 280,-551.49 310.75,-540.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.15,-543.89 320.42,-537.27 309.83,-537.29 312.15,-543.89\"/>\n",
       "</g>\n",
       "<!-- temperature -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>temperature</title>\n",
       "<text text-anchor=\"middle\" x=\"278\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">temperature=</text>\n",
       "</g>\n",
       "<!-- temperature&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>temperature&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.52,-575.7C308.87,-566.97 321.59,-556.24 332.84,-546.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"335.33,-549.23 340.72,-540.1 330.82,-543.88 335.33,-549.23\"/>\n",
       "</g>\n",
       "<!-- api_key -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>api_key</title>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">api_key=</text>\n",
       "</g>\n",
       "<!-- api_key&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>api_key&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M371.54,-575.7C370,-567.98 368.14,-558.71 366.42,-550.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"369.81,-549.22 364.42,-540.1 362.95,-550.6 369.81,-549.22\"/>\n",
       "</g>\n",
       "<!-- _mk_parser&#45;&gt;raw_dict_content -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>_mk_parser&#45;&gt;raw_dict_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361,-503.7C361,-495.98 361,-486.71 361,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.5,-478.1 361,-468.1 357.5,-478.1 364.5,-478.1\"/>\n",
       "</g>\n",
       "<!-- labeled_optional_content -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>labeled_optional_content</title>\n",
       "<text text-anchor=\"middle\" x=\"350\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">labeled_optional_content</text>\n",
       "</g>\n",
       "<!-- label_empty_content -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>label_empty_content</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"415.5,-252 284.5,-252 284.5,-216 415.5,-216 415.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"350\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">label_empty_content</text>\n",
       "</g>\n",
       "<!-- labeled_optional_content&#45;&gt;label_empty_content -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>labeled_optional_content&#45;&gt;label_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350,-287.7C350,-279.98 350,-270.71 350,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.5,-262.1 350,-252.1 346.5,-262.1 353.5,-262.1\"/>\n",
       "</g>\n",
       "<!-- optional_content -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>optional_content</title>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">optional_content=</text>\n",
       "</g>\n",
       "<!-- optional_content&#45;&gt;has_content_labelling -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>optional_content&#45;&gt;has_content_labelling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.36,-431.88C275.05,-422.72 294.56,-411.34 311.45,-401.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.66,-404.25 320.53,-396.19 310.13,-398.21 313.66,-404.25\"/>\n",
       "</g>\n",
       "<!-- has_content_labelling&#45;&gt;labeled_optional_content -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>has_content_labelling&#45;&gt;labeled_optional_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350,-359.7C350,-351.98 350,-342.71 350,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.5,-334.1 350,-324.1 346.5,-334.1 353.5,-334.1\"/>\n",
       "</g>\n",
       "<!-- labeled_empty_content -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>labeled_empty_content</title>\n",
       "<text text-anchor=\"middle\" x=\"352\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">labeled_empty_content</text>\n",
       "</g>\n",
       "<!-- labeled_empty_content&#45;&gt;translate_content -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>labeled_empty_content&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M323.38,-143.88C308.08,-134.72 289.06,-123.34 272.58,-113.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.11,-110.32 263.73,-108.19 270.52,-116.33 274.11,-110.32\"/>\n",
       "</g>\n",
       "<!-- empty_label -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>empty_label</title>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">empty_label=</text>\n",
       "</g>\n",
       "<!-- empty_label&#45;&gt;label_empty_content -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>empty_label&#45;&gt;label_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.49,-287.88C262.44,-278.47 286.13,-266.71 306.36,-256.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.97,-259.77 315.37,-252.19 304.86,-253.5 307.97,-259.77\"/>\n",
       "</g>\n",
       "<!-- label_empty_content&#45;&gt;labeled_empty_content -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>label_empty_content&#45;&gt;labeled_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.49,-215.7C350.71,-207.98 350.98,-198.71 351.23,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.72,-190.2 351.51,-180.1 347.73,-190 354.72,-190.2\"/>\n",
       "</g>\n",
       "<!-- translated_dict_content -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>translated_dict_content</title>\n",
       "<text text-anchor=\"middle\" x=\"235\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">translated_dict_content</text>\n",
       "</g>\n",
       "<!-- language -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>language</title>\n",
       "<text text-anchor=\"middle\" x=\"37\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">language=</text>\n",
       "</g>\n",
       "<!-- language&#45;&gt;translate_content -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>language&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.14,-147.21C77.13,-146.12 80.12,-145.04 83,-144 113.47,-133.06 147.49,-121.17 175.6,-111.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.98,-114.65 185.29,-108.07 174.69,-108.04 176.98,-114.65\"/>\n",
       "</g>\n",
       "<!-- language_list -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>language_list</title>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">language_list=</text>\n",
       "</g>\n",
       "<!-- language_list&#45;&gt;translate_content -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>language_list&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.24,-143.7C176.19,-134.8 190.92,-123.82 203.85,-114.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.1,-116.88 212.03,-108.1 201.92,-111.27 206.1,-116.88\"/>\n",
       "</g>\n",
       "<!-- chat -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>chat</title>\n",
       "<text text-anchor=\"middle\" x=\"235\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">chat=</text>\n",
       "</g>\n",
       "<!-- chat&#45;&gt;translate_content -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>chat&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235,-143.7C235,-135.98 235,-126.71 235,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238.5,-118.1 235,-108.1 231.5,-118.1 238.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- translate_content&#45;&gt;translated_dict_content -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>translate_content&#45;&gt;translated_dict_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235,-71.7C235,-63.98 235,-54.71 235,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238.5,-46.1 235,-36.1 231.5,-46.1 238.5,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fcb85c330d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smart_cv import dag_pipeline\n",
    "from smart_cv.base import mall\n",
    "dag = dag_pipeline[:\"translate_content\"]\n",
    "dag.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guillaume.pdf',\n",
       " 'SCH.pdf',\n",
       " 'q_header.docx',\n",
       " 'OUSSAMA belcaid_CV.pdf',\n",
       " 'CV_Jonathan.docx',\n",
       " 'CV_Elena.docx',\n",
       " 'quentin.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smart_cv.base import mall\n",
    "list(mall.cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'key_ingress_print_downloading_message_with_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimbed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/imbed/imbed/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Tools for imbeddings\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimbed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fixed_step_chunker, SegmentMapping\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimbed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m umap_2d_embeddings, cosine_similarity\n",
      "File \u001b[0;32m~/Documents/GitHub/imbed/imbed/util.py:30\u001b[0m\n\u001b[1;32m     22\u001b[0m GRAZE_DATA_DIR \u001b[38;5;241m=\u001b[39m get_app_data_folder(\n\u001b[1;32m     23\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(package_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraze\u001b[39m\u001b[38;5;124m'\u001b[39m), ensure_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m DFLT_SAVES_DIR \u001b[38;5;241m=\u001b[39m get_app_data_folder(\n\u001b[1;32m     26\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(package_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaves\u001b[39m\u001b[38;5;124m'\u001b[39m), ensure_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m graze_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     29\u001b[0m     rootdir\u001b[38;5;241m=\u001b[39mGRAZE_DATA_DIR,\n\u001b[0;32m---> 30\u001b[0m     key_ingress\u001b[38;5;241m=\u001b[39m\u001b[43m_graze\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_ingress_print_downloading_message_with_size\u001b[49m,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m graze \u001b[38;5;241m=\u001b[39m partial(_graze, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgraze_kwargs)\n\u001b[1;32m     33\u001b[0m grazed_path \u001b[38;5;241m=\u001b[39m partial(graze, return_filepaths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'key_ingress_print_downloading_message_with_size'"
     ]
    }
   ],
   "source": [
    "import imbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: dol 0.2.41\n",
      "Uninstalling dol-0.2.41:\n",
      "  Successfully uninstalled dol-0.2.41\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y dol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexis/Documents/GitHub/dol/dol/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import dol\n",
    "print(dol.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version dol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n----media/image1.png----Quentin Roman\\n\\nExpérience : Missing information\\n\\nDisponibilité : As soon as possible\\n\\nMobilité : Missing information\\n\\nSoftware Engineer\\nCompétences :\\n\\n\\nPython, C#, Java, JavaScript, Angular, Node, React, .NET, SQL, Git\\n\\nExpériences : \\n\\n\\nModel Training for Machine Learning: September 2022 - September 2023\\nAmadeus\\n\\nDeveloped Web-based Angular Application for Hospitality IT business\\n\\nmissions: \\nEnhanced internal Diagnostic tools with new features\\n\\nImplemented secure permissions system\\n\\nInvestigated and resolved production issues\\n\\n\\nStacks : C#, Unity, Python, Jupyter Notebook\\n\\nSoftware Development: September 2021 - February 2022\\nAalborg University\\n\\nDeveloped a VR application for medical purposes\\n\\nmissions: \\nConducted testing sessions involving students and patients\\n\\nOptimized code for enhanced performance\\n\\nAnalyzed eye-tracking data\\n\\n\\nStacks : Javascript, C#, Java\\n\\nNetwork Administration: January 2021 - June 2021\\nTournaire\\n\\nAdministered network systems and hardware configuration\\n\\nmissions: \\nImplemented Multi-Factor Authenticator for Cisco VPN\\n\\nInstalled Centralized Log Solution with Elasticsearch\\n\\n\\nStacks : Virtualization, Docker, Git, MongoDB, Linux\\n\\n\\nProjets personnels : \\n\\n\\nExperimenting VR Applications\\nLangues : \\n\\n\\nFrench, English\\nÉtudes : \\n\\n\\n\\n2018-2023 : Engineering Degree in Computer Science\\n    CESI - Nice\\n\\n\\n\\nIntérêts : \\n\\n\\nSoftware Development, Web Development, Database Management, Data Analysis, Project Planning, Git Management\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.cvs['q_header.docx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n----media/image1.png----Quentin Roman\\n\\nExpérience : Missing information\\n\\nDisponibilité : As soon as possible\\n\\nMobilité : Missing information\\n\\nSoftware Engineer\\nCompétences :\\n\\n\\nPython, C#, Java, JavaScript, Angular, Node, React, .NET, SQL, Git\\n\\nExpériences : \\n\\n\\nModel Training for Machine Learning: September 2022 - September 2023\\nAmadeus\\n\\nDeveloped Web-based Angular Application for Hospitality IT business\\n\\nmissions: \\nEnhanced internal Diagnostic tools with new features\\n\\nImplemented secure permissions system\\n\\nInvestigated and resolved production issues\\n\\n\\nStacks : C#, Unity, Python, Jupyter Notebook\\n\\nSoftware Development: September 2021 - February 2022\\nAalborg University\\n\\nDeveloped a VR application for medical purposes\\n\\nmissions: \\nConducted testing sessions involving students and patients\\n\\nOptimized code for enhanced performance\\n\\nAnalyzed eye-tracking data\\n\\n\\nStacks : Javascript, C#, Java\\n\\nNetwork Administration: January 2021 - June 2021\\nTournaire\\n\\nAdministered network systems and hardware configuration\\n\\nmissions: \\nImplemented Multi-Factor Authenticator for Cisco VPN\\n\\nInstalled Centralized Log Solution with Elasticsearch\\n\\n\\nStacks : Virtualization, Docker, Git, MongoDB, Linux\\n\\n\\nProjets personnels : \\n\\n\\nExperimenting VR Applications\\nLangues : \\n\\n\\nFrench, English\\nÉtudes : \\n\\n\\n\\n2018-2023 : Engineering Degree in Computer Science\\n    CESI - Nice\\n\\n\\n\\nIntérêts : \\n\\n\\nSoftware Development, Web Development, Database Management, Data Analysis, Project Planning, Git Management\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from msword import bytes_to_doc, get_text_from_docx\n",
    "from dol import Pipe\n",
    "from docx import Document\n",
    "\n",
    "def full_docx_decoder(doc_bytes):\n",
    "    text = get_text_from_docx(Document(doc_bytes))\n",
    "    doc = docx2python(doc_bytes)\n",
    "    added_header = '\\n\\n'.join(iter_paragraphs(doc.header)) + text\n",
    "    added_footer = added_header + '\\n\\n'.join(iter_paragraphs(doc.footer))\n",
    "    return added_footer\n",
    "\n",
    "decoder = Pipe(BytesIO,full_docx_decoder)\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    text = decoder(f.read())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n----media/image1.png----Quentin Roman\\n\\nExpérience : Missing information\\n\\nDisponibilité : As soon as possible\\n\\nMobilité : Missing information'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Document in module docx.document object:\n",
      "\n",
      "class Document(docx.shared.ElementProxy)\n",
      " |  Document(element: 'CT_Document', part: 'DocumentPart')\n",
      " |  \n",
      " |  WordprocessingML (WML) document.\n",
      " |  \n",
      " |  Not intended to be constructed directly. Use :func:`docx.Document` to open or create\n",
      " |  a document.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Document\n",
      " |      docx.shared.ElementProxy\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, element: 'CT_Document', part: 'DocumentPart')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add_heading(self, text: 'str' = '', level: 'int' = 1)\n",
      " |      Return a heading paragraph newly added to the end of the document.\n",
      " |      \n",
      " |      The heading paragraph will contain `text` and have its paragraph style\n",
      " |      determined by `level`. If `level` is 0, the style is set to `Title`. If `level`\n",
      " |      is 1 (or omitted), `Heading 1` is used. Otherwise the style is set to `Heading\n",
      " |      {level}`. Raises |ValueError| if `level` is outside the range 0-9.\n",
      " |  \n",
      " |  add_page_break(self)\n",
      " |      Return newly |Paragraph| object containing only a page break.\n",
      " |  \n",
      " |  add_paragraph(self, text: 'str' = '', style: 'str | ParagraphStyle | None' = None) -> 'Paragraph'\n",
      " |      Return paragraph newly added to the end of the document.\n",
      " |      \n",
      " |      The paragraph is populated with `text` and having paragraph style `style`.\n",
      " |      \n",
      " |      `text` can contain tab (``\\t``) characters, which are converted to the\n",
      " |      appropriate XML form for a tab. `text` can also include newline (``\\n``) or\n",
      " |      carriage return (``\\r``) characters, each of which is converted to a line\n",
      " |      break.\n",
      " |  \n",
      " |  add_picture(self, image_path_or_stream: 'str | IO[bytes]', width: 'int | Length | None' = None, height: 'int | Length | None' = None)\n",
      " |      Return new picture shape added in its own paragraph at end of the document.\n",
      " |      \n",
      " |      The picture contains the image at `image_path_or_stream`, scaled based on\n",
      " |      `width` and `height`. If neither width nor height is specified, the picture\n",
      " |      appears at its native size. If only one is specified, it is used to compute a\n",
      " |      scaling factor that is then applied to the unspecified dimension, preserving the\n",
      " |      aspect ratio of the image. The native size of the picture is calculated using\n",
      " |      the dots-per-inch (dpi) value specified in the image file, defaulting to 72 dpi\n",
      " |      if no value is specified, as is often the case.\n",
      " |  \n",
      " |  add_section(self, start_type: 'WD_SECTION' = <WD_SECTION_START.NEW_PAGE: 2>)\n",
      " |      Return a |Section| object newly added at the end of the document.\n",
      " |      \n",
      " |      The optional `start_type` argument must be a member of the :ref:`WdSectionStart`\n",
      " |      enumeration, and defaults to ``WD_SECTION.NEW_PAGE`` if not provided.\n",
      " |  \n",
      " |  add_table(self, rows: 'int', cols: 'int', style: 'str | _TableStyle | None' = None)\n",
      " |      Add a table having row and column counts of `rows` and `cols` respectively.\n",
      " |      \n",
      " |      `style` may be a table style object or a table style name. If `style` is |None|,\n",
      " |      the table inherits the default table style of the document.\n",
      " |  \n",
      " |  iter_inner_content(self) -> 'Iterator[Paragraph | Table]'\n",
      " |      Generate each `Paragraph` or `Table` in this document in document order.\n",
      " |  \n",
      " |  save(self, path_or_stream: 'str | IO[bytes]')\n",
      " |      Save this document to `path_or_stream`.\n",
      " |      \n",
      " |      `path_or_stream` can be either a path to a filesystem location (a string) or a\n",
      " |      file-like object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  core_properties\n",
      " |      A |CoreProperties| object providing Dublin Core properties of document.\n",
      " |  \n",
      " |  inline_shapes\n",
      " |      The |InlineShapes| collection for this document.\n",
      " |      \n",
      " |      An inline shape is a graphical object, such as a picture, contained in a run of\n",
      " |      text and behaving like a character glyph, being flowed like other text in a\n",
      " |      paragraph.\n",
      " |  \n",
      " |  paragraphs\n",
      " |      The |Paragraph| instances in the document, in document order.\n",
      " |      \n",
      " |      Note that paragraphs within revision marks such as ``<w:ins>`` or ``<w:del>`` do\n",
      " |      not appear in this list.\n",
      " |  \n",
      " |  part\n",
      " |      The |DocumentPart| object of this document.\n",
      " |  \n",
      " |  sections\n",
      " |      |Sections| object providing access to each section in this document.\n",
      " |  \n",
      " |  settings\n",
      " |      A |Settings| object providing access to the document-level settings.\n",
      " |  \n",
      " |  styles\n",
      " |      A |Styles| object providing access to the styles in this document.\n",
      " |  \n",
      " |  tables\n",
      " |      All |Table| instances in the document, in document order.\n",
      " |      \n",
      " |      Note that only tables appearing at the top level of the document appear in this\n",
      " |      list; a table nested inside a table cell does not appear. A table within\n",
      " |      revision marks such as ``<w:ins>`` or ``<w:del>`` will also not appear in the\n",
      " |      list.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from docx.shared.ElementProxy:\n",
      " |  \n",
      " |  __eq__(self, other: 'object')\n",
      " |      Return |True| if this proxy object refers to the same oxml element as does\n",
      " |      `other`.\n",
      " |      \n",
      " |      ElementProxy objects are value objects and should maintain no mutable local\n",
      " |      state. Equality for proxy objects is defined as referring to the same XML\n",
      " |      element, whether or not they are the same proxy object instance.\n",
      " |  \n",
      " |  __ne__(self, other: 'object')\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from docx.shared.ElementProxy:\n",
      " |  \n",
      " |  element\n",
      " |      The lxml element proxied by this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from docx.shared.ElementProxy:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from docx.shared.ElementProxy:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dag('Guillaume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python, Jupyter, Docker, GCP, Java, Spring, HTML, CSS, JavaScript'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[\"skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rules\n",
    "find missing stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>(beer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>(bread)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>(butter)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>(milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>(butter, bread)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>(milk, bread)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>(butter, milk)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support         itemsets\n",
       "0  0.444444           (beer)\n",
       "1  0.888889          (bread)\n",
       "2  0.777778         (butter)\n",
       "3  0.666667           (milk)\n",
       "4  0.666667  (butter, bread)\n",
       "5  0.555556    (milk, bread)\n",
       "6  0.444444   (butter, milk)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apriori algorithm\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Create sequences of transactions\n",
    "transactions = [\n",
    "    ['bread', 'milk', 'beer'],\n",
    "    ['bread', 'butter', 'beer'],\n",
    "    ['milk', 'butter', 'beer'],\n",
    "    ['bread', 'milk', 'butter'],\n",
    "    ['bread', 'milk'],\n",
    "    ['bread', 'butter'],\n",
    "    ['bread', 'butter'],\n",
    "    ['bread', 'milk', 'butter', 'beer'],\n",
    "    ['bread', 'milk', 'butter']\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "\n",
    "# Apply the Apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.4, use_colnames=True)\n",
    "frequent_itemsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missed content when parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from meshed import DAG\n",
    "from oa import prompt_function, chat\n",
    "from functools import partial\n",
    "template = \"I will give you a text extracted from a pdf but with errors like unwated spaces or special characters. You will have to clean it and return the cleaned text. Here is the text: \\n\\n{content}\\n\\nPlease clean it and return the cleaned text.\"\n",
    "my_chat = partial(chat, temperature=0)\n",
    "f = prompt_function(template, prompt_func=my_chat)\n",
    "\n",
    "def concat_json_text(d:dict)->str:\n",
    "    text = \"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            text += concat_json_text(value)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    text += concat_json_text(item)\n",
    "                else:\n",
    "                    text += str(item) + \", \"\n",
    "        else:\n",
    "            text +=  str(value) + \", \"\n",
    "    return f(content=text)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def text(concat_json_text:str)->str:\n",
    "    return concat_json_text\n",
    "\n",
    "\n",
    "def lemmentizer(text:str)->list[str]:\n",
    "    # Tokenisation des mots dans le texte\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Initialisation du lemmatiseur WordNet\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Récupération des mots vides (stop words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Ponctuations à ignorer\n",
    "    punkt = {'.', ',', ';', '!', '?', ':', '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '-', '_', '+', '=', '*', '&', '^', '%', '$', '#', '@', '~', '`', \"'\", '\"'}\n",
    "    \n",
    "    # Lemmatisation des mots en ignorant les mots vides\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.lower() not in stop_words and word not in punkt]\n",
    "    \n",
    "    return lemmatized_words\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# text = \"I am a developer and I am Working on a project TO develop a NEW application !&&\"\n",
    "# lemmas = lemmentizer(text)\n",
    "# print(lemmas)\n",
    "\n",
    "def symetric_difference(text1, text2):\n",
    "    return set(lemmentizer(text1)).symmetric_difference(set(lemmentizer(text2)))\n",
    "\n",
    "def intersection(text1, text2):\n",
    "    if isinstance(text1, str):\n",
    "        set1 = set(lemmentizer(text1))\n",
    "    else:\n",
    "        set1 = text1\n",
    "    if isinstance(text2, str):\n",
    "        set2 = set(lemmentizer(text2))\n",
    "    else:\n",
    "        set2 = text2\n",
    "    return set1.intersection(set2)\n",
    "\n",
    "def missing_words(original_text:str, copy:str)->set:\n",
    "    return set(lemmentizer(original_text)).difference(set(lemmentizer(copy)))\n",
    "\n",
    "# text1 = \"Rédaction de rapports\"\n",
    "# text2 = \"lecture des rapports\"\n",
    "\n",
    "# symetric_difference(text1, text2)\n",
    "# print(intersection(text1, text2))\n",
    "# print(missing_words(text1, text2))\n",
    "\n",
    "def missed_content(original_text:str, json_content:dict):\n",
    "    json_text = concat_json_text(json_content)\n",
    "    return symetric_difference(original_text, json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = missed_content(mall.cvs['quentin.pdf'], content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'French\\nEnglish\\n› TOEIC : 975/990\\nExperimen ting VR\\nApplica tions\\n(C# / U nity)\\nModel Training f or\\nMachine L earning\\nexperimen tation with a\\nsmall D atase t\\n(Python / Jupyter\\nNotebook)\\nData Backup and\\nEncryp tion S oftware\\n(C# / WPF  / MVVM)\\nLanguag es\\nJavascrip t, C#, Java,\\nPython, PHP , C++, C\\nFrame work\\nAngular , Node, Lar avel,\\nReact, S pring, Expr ess,\\n.NET\\nCommon\\nVirtualiza tion, D ocker, Git,\\nMongoDB, Linux, Virtual\\nReality , SQL, D ata Scienc e\\nSoft\\nProblem-S olving,\\nAdaptability , Attention t o\\nDetail, S elf-MotivationQuentin ROMAN\\nLooking f or a Job in S oftware Developmen t\\nNewly Gradua ted Software Engineer , Team Worker, Motivated and\\nPassiona te with ne w Technolo gies.\\nEngineering D egree in C omput er Scienc e\\nCESI  Nice From 2018  to 2023\\nAcademic B ackgr ound\\n• Network Administr ation        • Cyber  Security\\n• Software Developmen t           • Web D evelopmen t\\n• Database M anag emen t             • Data Analysis\\n• Project P lanning                                      • Git Manag emen t\\nWeb D evelopmen t\\nAmadeus  Sophia Antipolis  From September  2022  to September  2023\\nDeveloped Web-based Angular  Applica tion f or Hospitality  IT business\\nEnhanc ed in ternal D iagnostic t ools with ne w features to impr ove user\\nexperienc e\\nImplemen ted a secur e permissions s ystem f or managing user  data ac cess\\nCollabor ated within an Agile de velopmen t environmen t (SCR UM)\\nInvestiga ted and r esolv ed pr oduction issues thr ough P roblem Trouble\\nReport (PTR)\\nSoftware Developmen t\\nAalbor g University Denmark  From September  2021  to February  2022\\nDeveloped a VR applica tion f or medical purposes, aiding in the r ecovery of\\nstroke pa tients.\\nConduct ed testing sessions in volving studen ts and pa tients to gather\\nfeedback and r eﬁne the applica tion.\\nOptimiz ed code and implemen ted multi-thr eading t echniques f or\\nenhanc ed perf ormanc e.\\nAnalyz ed eye-tracking da ta for user  interaction insigh ts.\\nNetwork Administr ation\\nTournair e Grasse, F rance From January  2021  to June 2021\\nAdminist ered ne twork s ystems, including har dware conﬁgur ation and\\ninstalla tion.\\nImplemen ted a M ulti-F actor Authen ticator for Cisc o VPN.\\nInstalled a C entralized Log Solution with E lasticsear ch for eﬃcien t log\\nmanag emen t.\\nManag ed and main tained Virtual M achines using VMware vSpher e.\\nTroubleshoo ted ne twork and s ystem issues.quen tin.roman7@gmail.c om \\uf0e0\\n 23 y ears old \\uf073 Cannes, Sophia-A ntipolis, Nice \\uf041\\n +33 6 51 20 20 82 \\uf098\\n- - \\n- - \\n- - \\n- - LANGUAGES\\nPERSONNAL\\nPROJECTS\\nSKILLSEDUCATION\\nWORK EXPERIENCE'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.cvs['quentin.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FullName': 'Guillaume Bernard',\n",
       " 'JobTitle': 'Ingénieur Backend Junior',\n",
       " 'avaibility': 'dès aujourd’hui',\n",
       " 'mobility': 'Missing information',\n",
       " 'seniority': 'Missing information',\n",
       " 'skills': 'Python, Java, Docker, Bash',\n",
       " 'certifications': 'Certificat en Anglais Avancé (C1)',\n",
       " 'experiences': [{'title': 'Ingénieur Backend Junior',\n",
       "   'company': 'Beewey Consulting',\n",
       "   'dates': '2023 - 3 mois',\n",
       "   'description': 'Migration de données, développement cloud, microservices, API',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'C, JSON, Flask, Terraform, VSCode'},\n",
       "  {'title': 'Ingénieur Fiabilité de Site',\n",
       "   'company': 'Thales DIS',\n",
       "   'dates': '2022 - 1 an',\n",
       "   'description': 'Service de gestion des incidents',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'},\n",
       "  {'title': 'Maitre-Nageur',\n",
       "   'company': 'Aqualand, Parc Aquatique',\n",
       "   'dates': '2020',\n",
       "   'description': 'Surveillant de baignade',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'}],\n",
       " 'personal_projects': 'Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC',\n",
       " 'languages': 'Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)',\n",
       " 'education': [{'diploma': 'Master en Big Data, Cloud Computing, Développement Logiciel',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2020-2022'},\n",
       "  {'diploma': 'Licence en Sciences Informatiques & Electronique',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2017-2020'},\n",
       "  {'diploma': 'Baccalauréat Scientifique – Mention Bien',\n",
       "   'school': 'Lycée Jean Moulin',\n",
       "   'dates': '2014-2017'}],\n",
       " 'interests': 'Data au sens large, Data Mining, Statistiques, Apprentissage Automatique, Arts Martiaux',\n",
       " 'has_certifications': True,\n",
       " 'has_personal_projects': True,\n",
       " 'has_interests': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from oa.base import chat\n",
    "my_chat = partial(chat, model=\"gpt-4\")\n",
    "f = prompt_function(template, prompt_func=my_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content retrieved:  {'FullName': 'Quentin Roman', 'JobTitle': 'Software Engineer', 'avaibility': 'Immediately', 'mobility': 'none', 'seniority': 'Newly Graduated', 'skills': 'Python, C#, Java, JavaScript, Angular, Node, React, .NET, SQL, Git, MongoDB, Linux, Virtual Reality', 'certifications': 'none', 'experiences': [{'title': 'Software Development', 'company': 'Aalborg University Denmark', 'dates': 'September 2021 - February 2022', 'description': 'Developed a VR application for medical purposes, aiding in the recovery of stroke patients.', 'tasks': ['Conducted testing sessions involving students and patients to gather feedback and refine the application', 'Optimized code and implemented multi-threading techniques for enhanced performance', 'Analyzed eye-tracking data for user interaction insights'], 'tools': 'Python, C#, VR technologies'}, {'title': 'Network Administration', 'company': 'Tournaire Grasse, France', 'dates': 'January 2021 - June 2021', 'description': 'Administered network systems, including hardware configuration and installation.', 'tasks': ['Implemented a Multi-Factor Authenticator for Cisco VPN', 'Installed a Centralized Log Solution with Elasticsearch for efficient log management', 'Managed and maintained Virtual Machines using VMware vSphere'], 'tools': 'Networking tools, Cisco VPN, VMware'}, {'title': 'Web Development', 'company': 'Amadeus Sophia Antipolis', 'dates': 'September 2022 - September 2023', 'description': 'Developed Web-based Angular Application for Hospitality IT business.', 'tasks': ['Enhanced internal diagnostic tools with new features to improve user experience', 'Implemented a secure permissions system for managing user data access'], 'tools': 'Angular, Web development technologies'}], 'personal_projects': 'none', 'languages': 'French, English', 'education': [{'diploma': 'Engineering Degree in Computer Science', 'school': 'CESI Nice', 'dates': '2018 - 2023'}], 'interests': 'Virtual Reality, Software Development, Networking, Web Development'}\n"
     ]
    }
   ],
   "source": [
    "keywords = mall.config['stacks_keywords.txt']\n",
    "\n",
    "original = f(mall.cvs['quentin.pdf'])\n",
    "\n",
    "retreived = concat_json_text(dag('quentin.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'september', 'optimized', 'science', 'involving', 'dataset', 'experimenting', 'grasse', 'engineer', 'technique', 'experience', '2018', 'backup', 'self-motivation', 'cisco', 'efficient', 'notebook', 'production', 'environment', 'angular', 'planning', 'recovery', 'performance', 'june', 'using', 'patient', 'web', 'purpose', 'aiding', 'model', 'newly', 'git', 'attention', 'centralized', 'encryption', 'skill', 'multi-factor', 'nice', 'soft', 'permission', 'january', 'refine', 'system', '975/990', 'medical', 'enhanced', 'authenticator', 'university', 'experimentation', 'investigated', 'tool', 'issue', 'virtual', 'administered', 'implemented', 'conducted', 'collaborated', 'maintained', 'student', 'application', 'virtualization', 'ptr', 'vsphere', 'vpn', 'gather', 'installation', 'jupyter', 'software', 'multi-threading', 'mongodb', 'session', 'tournaire', 'access', 'french', 'linux', 'problem', 'graduated', 'cesi', 'report', '20', 'motivated', 'trouble', 'computer', 'laravel', 'express', 'job', 'management', 'degree', 'february', 'installed', 'technology', 'business', 'engineering', 'troubleshooted', 'year', 'development', 'resolved', 'vr', 'passionate', 'hardware', 'quentin.roman7', '23', 'analysis', 'spring', 'sophia-antipolis', 'problem-solving', '51', 'agile', 'mvvm', 'academic', 'internal', 'within', 'including', 'training', 'sophia', 'analyzed', 'vmware', '6', 'developed', 'user', 'secure', 'managing', 'detail', 'amadeus', 'reality', 'stroke', 'framework', 'web-based', 'roman', '+33', 'scrum', 'unity', '.net', 'testing', 'configuration', 'insight', 'solution', 'small', 'antipolis', 'new', 'worker', 'feedback', 'code', 'administration', 'hospitality', 'france', 'elasticsearch', 'node', 'react', 'aalborg', 'javascript', 'toeic', 'looking', 'interaction', 'gmail.com', 'cannes', 'eye-tracking', '82', 'database', 'background', 'language', 'common', 'old', 'log', 'denmark', 'wpf', 'cyber', 'adaptability', 'english', 'c++', 'team', 'network', 'managed', 'improve', 'project', 'php', 'sql', 'quentin', '2021', 'diagnostic', 'feature', 'security'}\n",
      "{'project', 'sql', 'php', 'express', 'spring', 'agile', 'git', 'team', 'testing', '.net', 'management', 'scrum', 'react', 'javascript', 'angular', 'computer'}\n"
     ]
    }
   ],
   "source": [
    "retreived = concat_json_text(second_dict)\n",
    "missed = missing_words(original, retreived)\n",
    "missed_keywords = intersection(keywords, missed)\n",
    "print(missed)\n",
    "print(missed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_correction = \"\"\"I will give you a resume and some keywords you have to find in the resume. Then fill my json with the keywords\n",
    "Here is the resume: \\n\\n{resume}\\n\\nHere are the keywords: \\n\\n{keywords}\\n\\nHere is the json: \\n\\n{json}\\n\\nPlease fill the json with the keywords and preserve the json format with double quotes.\n",
    "Keep all the initial content of my json and add the missing keywords.\"\"\"\n",
    "\n",
    "second_fill = prompt_function(template_correction)\n",
    "\n",
    "second_json = second_fill(resume=original, keywords=missed_keywords, json=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"FullName\": \"Guillaume Bernard\",\\n    \"JobTitle\": \"Ingénieur Backend Junior\",\\n    \"avaibility\": \"dès aujourd’hui\",\\n    \"mobility\": \"Missing information\",\\n    \"seniority\": \"Missing information\",\\n    \"skills\": \"Python, Java, Docker, Bash\",\\n    \"certifications\": \"Certificat d\\'anglais avancé (C1)\",\\n    \"experiences\": [\\n        {\\n            \"title\": \"Ingénieur Backend Junior\",\\n            \"company\": \"Beewey Consulting\",\\n            \"dates\": \"2023 - 3 mois\",\\n            \"description\": \"Migration de données, développement cloud, microservices, API\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"C, JSON, Flask, Terraform, VSCode\"\\n        },\\n        {\\n            \"title\": \"Ingénieur Fiabilité de Site\",\\n            \"company\": \"Thales DIS\",\\n            \"dates\": \"2022 - 1 an\",\\n            \"description\": \"Service de gestion des incidents\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"Missing information\"\\n        },\\n        {\\n            \"title\": \"Maitre-Nageur\",\\n            \"company\": \"Aqualand, Parc Aquatique\",\\n            \"dates\": \"2020 - 3 mois\",\\n            \"description\": \"Surveillant de baignade\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"Missing information\"\\n        }\\n    ],\\n    \"personal_projects\": \"Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC\",\\n    \"languages\": \"Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)\",\\n    \"education\": [\\n        {\\n            \"diploma\": \"Master\",\\n            \"school\": \"ISEN Ecole d’Ingénieur\",\\n            \"dates\": \"2020 - 2022\"\\n        },\\n        {\\n            \"diploma\": \"Licence\",\\n            \"school\": \"ISEN Ecole d’Ingénieur\",\\n            \"dates\": \"2017 - 2020\"\\n        },\\n        {\\n            \"diploma\": \"Baccalauréat Scientifique\",\\n            \"school\": \"Lycée Jean Moulin\",\\n            \"dates\": \"2014 - 2017\"\\n        }\\n    ],\\n    \"interests\": \"Data au sens large, Data Mining, Statistiques, Machine Learning, Arts Martiaux\",\\n    \"has_certifications\": true,\\n    \"has_personal_projects\": true,\\n    \"has_interests\": true,\\n    \"keywords\": [\"php\", \"sql\", \"spring\", \"express\", \"git\", \"testing\", \".net\", \"react\", \"javascript\", \"angular\", \"computer\"]\\n}'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "second_dict = json.loads(second_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FullName': 'Guillaume Bernard',\n",
       " 'JobTitle': 'Ingénieur Backend Junior',\n",
       " 'avaibility': 'dès aujourd’hui',\n",
       " 'mobility': 'Missing information',\n",
       " 'seniority': 'Missing information',\n",
       " 'skills': 'Python, Java, Docker, Bash',\n",
       " 'certifications': \"Certificat d'anglais avancé (C1)\",\n",
       " 'experiences': [{'title': 'Ingénieur Backend Junior',\n",
       "   'company': 'Beewey Consulting',\n",
       "   'dates': '2023 - 3 mois',\n",
       "   'description': 'Migration de données, développement cloud, microservices, API',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'C, JSON, Flask, Terraform, VSCode'},\n",
       "  {'title': 'Ingénieur Fiabilité de Site',\n",
       "   'company': 'Thales DIS',\n",
       "   'dates': '2022 - 1 an',\n",
       "   'description': 'Service de gestion des incidents',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'},\n",
       "  {'title': 'Maitre-Nageur',\n",
       "   'company': 'Aqualand, Parc Aquatique',\n",
       "   'dates': '2020 - 3 mois',\n",
       "   'description': 'Surveillant de baignade',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'}],\n",
       " 'personal_projects': 'Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC',\n",
       " 'languages': 'Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)',\n",
       " 'education': [{'diploma': 'Master',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2020 - 2022'},\n",
       "  {'diploma': 'Licence',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2017 - 2020'},\n",
       "  {'diploma': 'Baccalauréat Scientifique',\n",
       "   'school': 'Lycée Jean Moulin',\n",
       "   'dates': '2014 - 2017'}],\n",
       " 'interests': 'Data au sens large, Data Mining, Statistiques, Machine Learning, Arts Martiaux',\n",
       " 'has_certifications': True,\n",
       " 'has_personal_projects': True,\n",
       " 'has_interests': True,\n",
       " 'project': True,\n",
       " 'agile': True,\n",
       " 'team': True,\n",
       " 'scrum': True,\n",
       " 'management': True}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_ai_request(reque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.33.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (1.24.0)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (8.2.3)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (4.9.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.18.0-cp39-cp39-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.0-cp39-cp39-macosx_10_12_x86_64.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.1/336.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: toolz, toml, smmap, rpds-py, mdurl, blinker, referencing, pydeck, markdown-it-py, gitdb, rich, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.3.0 blinker-1.7.0 gitdb-4.0.11 gitpython-3.1.43 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 pydeck-0.8.1b0 referencing-0.34.0 rich-13.7.1 rpds-py-0.18.0 smmap-5.0.1 streamlit-1.33.0 toml-0.10.2 toolz-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      👋 \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "      If you’d like to receive helpful onboarding emails, news, offers, promotions,\n",
      "      and the occasional swag, please enter your email address below. Otherwise,\n",
      "      leave this field blank.\n",
      "\n",
      "      \u001b[34mEmail: \u001b[0m ^C\n",
      "2024-04-08 14:50:52.599 \n"
     ]
    }
   ],
   "source": [
    "!streamlit run /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages/ipykernel_launcher.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_cv import ContentRetriever\n",
    "import json \n",
    "keywords_text = \"\"\"Python, C,, Perl, Ruby, MatLab, Mathematica, Assembleur, VB, XML, Java, JEE, J2EE, JavaScript, PHP, R,, CSS, C\\+\\+, IOS, Swift, Android, Kotlin, Flutter, Dart, Rust, Ionic, Cordova, Reactnative, Xamarin, Babylon.js, C\\#, F\\#, WordPress, ThreeJS, WebGL,\n",
    "TensorFlow, Spark, Spring, Angular, Structs, Ember, Vue, Django, React, .NET,, .NET Core, Cocoapods, Osgi, Selenium, QA, Nest, Express, Symphony, Falcon, ASP.NET, WinDev, Flask, PySpark, Hibernate,\n",
    "Hive, Impala, Oracle, MySQL, Acess, SQL, SQL Server, PostgreSQL, Mongo, MariaDB, DBA,\n",
    "API, Unit Testing, Test Unitaire, Azure, Docker, Bamboo, Kubernetes, Jenkins, Jasmine, Karma, MVC, AWS,\n",
    "Git, Tortoise, TFS, CVS, SVN, MVC, GNU RCS, GNU CSSC, CVSNT, GNU arch, Darcs, DCVS, Monotone, Codeville, Mercurial, Bazaar, Fossil, Veracity, Pijul, SCCS, PVCS, Rational ClearCase, Harvest, CMVC, Visual SourceSafe, AccuRev SCM, Sourceanywhere, Team Foundation Server, Rational Synergy, Rational Team Concert, BitKeeper, Plastic SCM, IIS active directory, 2IS,\n",
    "Datawarehouse, Machine Learning, NLP, DeepLearning, Réseau de Neurones, kNN, k\\-NN, Régression Linéaire, SVM, Régression Logistique, Arbre de Décission, Fôrets Aléatoires, gradient boosting, PCA, Analyse en Composantes Principales, DataLake, DataFactory, PowerBI, Tableau, Qlikesense, GCP, OpenCV, Computer Vision, \n",
    "Gestion, Organization, Management, Agile, Scrum, Trello, JIRA, MS Project, Confluence, Sprint, GANTT, Specifications, Redaction, Cahier de charges, Workshop, Atelier, AMOA, PMO\"\"\"\n",
    "with open(\"prompt_dict.json\", \"r\") as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "def match_kewords(keywords_text, text):\n",
    "    \"\"\" Returns \"\"\"\n",
    "    keywords = keywords_text.split(\", \")\n",
    "    kw_list = []\n",
    "    for kw in keywords:\n",
    "        if kw in text:\n",
    "            if kw in [\"R,\", \"C,\"]:\n",
    "                continue\n",
    "            kw_list.append(kw)\n",
    "    for letter in [\"R\", \"C\"]:\n",
    "        for specials in [\" {letter}.\", \" {letter},\", \" {letter} \"]:\n",
    "            if specials in text:\n",
    "                kw_list.append(letter)\n",
    "    return kw_list\n",
    "\n",
    "def keywords_score(matched, pred):\n",
    "    pred = [kw.lower() for kw in pred]\n",
    "    score = 0\n",
    "    sames = []\n",
    "    missed = []\n",
    "    for kw in matched:\n",
    "        if kw.lower() in pred:\n",
    "            score += 1\n",
    "            sames.append(kw)\n",
    "        else:\n",
    "            missed.append(kw)\n",
    "    score = score / len(matched)\n",
    "    return score, sames, missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'Perl', 'Java', 'Selenium', 'Express', 'Azure', 'Docker', 'Kubernetes', 'Jenkins', 'SVN']\n"
     ]
    }
   ],
   "source": [
    "print(match_kewords(keywords_text, parser.dict_content[\"competences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match_kewords(keywords_text, parser.dict_content[\"competences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guillaume.pdf', 'SCH.pdf', 'Adil.pdf', 'Nappee-Thomas.pdf', 'Thor_Whalen_CV.pdf']\n",
      "\n",
      "processing Guillaume.pdf\n",
      "matched: ['Python', 'Java', 'JavaScript', 'CSS', 'Spring', 'Flask', 'SQL', 'PostgreSQL', 'Docker', 'GCP']\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': {'message': 'Failed to create completion as the model generated invalid Unicode output. Unfortunately, this can happen in rare situations. Consider reviewing your prompt or reducing the temperature of your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_eccc43ef3a5318f641401cc799dbf0e4 in your message.)', 'type': 'server_error', 'param': None, 'code': 'invalid_model_output'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m matched \u001b[38;5;241m=\u001b[39m match_kewords(keywords_text, fullcontent)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatched: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatched\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m llm_keywords \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mdict_content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompetences\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_keywords: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_keywords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/smart_cv/smart_cv/ResumeParser.py:114\u001b[0m, in \u001b[0;36mContentRetriever.retrieve_content\u001b[0;34m(self, json_string, inplace, verbose)\u001b[0m\n\u001b[1;32m     49\u001b[0m     json_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts\n\u001b[1;32m     50\u001b[0m content_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124m        I will give you a resume and you will fill the provided json. \u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m        The keys have to be respected and the corresponding description will be replaced by the retrieved information.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124m        Gestion, Organization, Management, Agile, Scrum, Trello, JIRA, MS Project, Confluence, Sprint, GANTT, Specifications, Redaction, Cahier de charges, Workshop, Atelier, AMOA, PMO\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(content)\n",
      "File \u001b[0;32m~/Documents/GitHub/smart_cv/file_dialoger.py:74\u001b[0m, in \u001b[0;36mFile_Dialoger.ask_question\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_question\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain is not set. Please set it with build_chain method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion_variable\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/runnables/base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:166\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    163\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    165\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    175\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:544\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    543\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:438\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    433\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m }\n\u001b[0;32m--> 438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'error': {'message': 'Failed to create completion as the model generated invalid Unicode output. Unfortunately, this can happen in rare situations. Consider reviewing your prompt or reducing the temperature of your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_eccc43ef3a5318f641401cc799dbf0e4 in your message.)', 'type': 'server_error', 'param': None, 'code': 'invalid_model_output'}}"
     ]
    }
   ],
   "source": [
    "#get list of files in directory\n",
    "import os\n",
    "directory = \"../smart_cv/data/cvs\"\n",
    "files = os.listdir(directory)\n",
    "# remove .DS_Store file\n",
    "files.remove(\".DS_Store\")\n",
    "print(files)\n",
    "key = \"your key here\"\n",
    "avg_score = 0\n",
    "for cv_file in files:\n",
    "    print(f\"\\nprocessing {cv_file}\")\n",
    "    parser = ContentRetriever(cv_path=directory+\"/\"+cv_file, api_key=key,\n",
    "                    prompts=prompt_dict, chunk_size=20000, chunk_overlap=0, temperature=1.5, k=5)\n",
    "\n",
    "    fullcontent = \"\" \n",
    "    for doc in parser.documents:\n",
    "        fullcontent += doc.page_content\n",
    "\n",
    "    matched = match_kewords(keywords_text, fullcontent)\n",
    "    print(f\"matched: {matched}\")\n",
    "    parser.retrieve_content(verbose=False)\n",
    "\n",
    "    llm_keywords = parser.dict_content[\"competences\"].split(\", \")\n",
    "    print(f\"llm_keywords: {llm_keywords}\")\n",
    "    score, intersection, missed = keywords_score(matched, llm_keywords)\n",
    "    avg_score += score\n",
    "    print(f\"score: {score},\\n intersection: {intersection},\\n missed: {missed}\")\n",
    "\n",
    "avg_score = avg_score / len(files)\n",
    "print(f\"average score: {avg_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature=0 => avg score = 0.327\n",
    "Temperature=0.5 => avg score = 0.27\n",
    "Temperature=1 => avg score = 0.30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check content with instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "            \"Less than 11 bullet points for each experience\",\n",
    "            \"More than 3 bullet points for each experience\",\n",
    "            \"Framework versions have to be mentioned\",\n",
    "            \"Tasks done during experiences have to be mentioned\",\n",
    "            \"Context of the projects have to be mentioned: like dates, role, team size, company size, etc\",\n",
    "            \"Technical stacks have to be mentioned in experiences\",\n",
    "            \"There has to be contact information\",\n",
    "            \"If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.CriteriaChecker import CriteriaChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CriteriaChecker(instructions, parser.dict_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Less than 11 bullet points for each experience': True,\n",
       " 'More than 3 bullet points for each experience': True,\n",
       " 'Framework versions have to be mentioned': True,\n",
       " 'Tasks done during experiences have to be mentioned': True,\n",
       " 'Context of the projects have to be mentioned: like dates, role, team size, company size, etc': True,\n",
       " 'Technical stacks have to be mentioned in experiences': True,\n",
       " 'There has to be contact information': True,\n",
       " 'If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.add_criterion(\"French or English language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Less than 11 bullet points for each experience': True,\n",
       " 'More than 3 bullet points for each experience': True,\n",
       " 'Framework versions have to be mentioned': True,\n",
       " 'Tasks done during experiences have to be mentioned': True,\n",
       " 'Context of the projects have to be mentioned: like dates, role, team size, company size, etc': True,\n",
       " 'Technical stacks have to be mentioned in experiences': True,\n",
       " 'There has to be contact information': True,\n",
       " 'If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link': True,\n",
       " 'French or English language': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.status  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcc\u001b[49m\u001b[38;5;241m.\u001b[39mfeedback()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "cc.feedback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
