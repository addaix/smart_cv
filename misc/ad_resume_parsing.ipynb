{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaible CVs in the app:  ['Guillaume.pdf', 'SCH.pdf', 'OUSSAMA belcaid_CV.pdf', 'CV_Jonathan.docx', 'CV_Elena.docx', 'quentin.pdf']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"740pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 740.00 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 736,-472 736,4 -4,4\"/>\n",
       "<!-- cv_text -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>cv_text</title>\n",
       "<text text-anchor=\"middle\" x=\"28\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text</text>\n",
       "</g>\n",
       "<!-- cv_content_ -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>cv_content_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"318.5,-252 235.5,-252 235.5,-216 318.5,-216 318.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_content_</text>\n",
       "</g>\n",
       "<!-- cv_text&#45;&gt;cv_content_ -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>cv_text&#45;&gt;cv_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.06,-291.45C59.05,-290.21 62.07,-289.03 65,-288 118.52,-269.2 181.84,-254.28 225.25,-245.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.22,-248.5 235.29,-243.03 224.79,-241.64 226.22,-248.5\"/>\n",
       "</g>\n",
       "<!-- cv_name -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>cv_name</title>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_name</text>\n",
       "</g>\n",
       "<!-- cv_text_ -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>cv_text_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274.5,-396 211.5,-396 211.5,-360 274.5,-360 274.5,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text_</text>\n",
       "</g>\n",
       "<!-- cv_name&#45;&gt;cv_text_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>cv_name&#45;&gt;cv_text_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.58,-431.7C262.21,-423.81 258.13,-414.3 254.38,-405.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"257.49,-403.92 250.33,-396.1 251.05,-406.67 257.49,-403.92\"/>\n",
       "</g>\n",
       "<!-- fill_template_ -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>fill_template_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"603.5,-108 510.5,-108 510.5,-72 603.5,-72 603.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">fill_template_</text>\n",
       "</g>\n",
       "<!-- cv_name&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>cv_name&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M306.04,-445.28C372.92,-435.73 518,-403.85 518,-307 518,-307 518,-307 518,-233 518,-191.56 533.64,-145.67 545.11,-117.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"548.45,-118.65 549.11,-108.07 542,-115.93 548.45,-118.65\"/>\n",
       "</g>\n",
       "<!-- cv_text_&#45;&gt;cv_text -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>cv_text_&#45;&gt;cv_text</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.37,-369.03C177.39,-360.16 121.75,-344.72 65.81,-324.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.7,-320.65 56.11,-320.41 64.24,-327.2 66.7,-320.65\"/>\n",
       "</g>\n",
       "<!-- cv_content -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>cv_content</title>\n",
       "<text text-anchor=\"middle\" x=\"394\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_content</text>\n",
       "</g>\n",
       "<!-- cv_content&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>cv_content&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M432.22,-144.59C454.81,-134.88 483.66,-122.5 507.93,-112.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"509.51,-115.2 517.32,-108.04 506.75,-108.77 509.51,-115.2\"/>\n",
       "</g>\n",
       "<!-- language -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>language</title>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">language=</text>\n",
       "</g>\n",
       "<!-- language&#45;&gt;cv_content_ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>language&#45;&gt;cv_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.25,-289.29C171.56,-279.46 201.87,-266.68 227.23,-255.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.82,-259.11 236.68,-252 226.1,-252.66 228.82,-259.11\"/>\n",
       "</g>\n",
       "<!-- chunk_overlap -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>chunk_overlap</title>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunk_overlap=</text>\n",
       "</g>\n",
       "<!-- chunk_overlap&#45;&gt;cv_content_ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>chunk_overlap&#45;&gt;cv_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.34,-287.7C240.29,-279.3 248.77,-269.07 256.4,-259.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.14,-262.04 262.83,-252.1 253.75,-257.57 259.14,-262.04\"/>\n",
       "</g>\n",
       "<!-- temperature -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>temperature</title>\n",
       "<text text-anchor=\"middle\" x=\"335\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">temperature=</text>\n",
       "</g>\n",
       "<!-- temperature&#45;&gt;cv_content_ -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>temperature&#45;&gt;cv_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.66,-287.7C313.71,-279.3 305.23,-269.07 297.6,-259.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.25,-257.57 291.17,-252.1 294.86,-262.04 300.25,-257.57\"/>\n",
       "</g>\n",
       "<!-- empty_label -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>empty_label</title>\n",
       "<text text-anchor=\"middle\" x=\"444\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">empty_label=</text>\n",
       "</g>\n",
       "<!-- empty_label&#45;&gt;cv_content_ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>empty_label&#45;&gt;cv_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.15,-287.88C380.22,-278.26 351.42,-266.19 327.13,-256.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.3,-252.71 317.72,-252.07 325.59,-259.16 328.3,-252.71\"/>\n",
       "</g>\n",
       "<!-- cv_content_&#45;&gt;cv_content -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>cv_content_&#45;&gt;cv_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.62,-215.88C320.92,-206.72 339.94,-195.34 356.42,-185.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.48,-188.33 365.27,-180.19 354.89,-182.32 358.48,-188.33\"/>\n",
       "</g>\n",
       "<!-- fill_template -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>fill_template</title>\n",
       "<text text-anchor=\"middle\" x=\"557\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">fill_template</text>\n",
       "</g>\n",
       "<!-- template_path -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>template_path</title>\n",
       "<text text-anchor=\"middle\" x=\"597\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">template_path=</text>\n",
       "</g>\n",
       "<!-- template_path&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>template_path&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M587.11,-143.7C582.51,-135.64 576.94,-125.89 571.85,-116.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"574.77,-115.05 566.77,-108.1 568.7,-118.52 574.77,-115.05\"/>\n",
       "</g>\n",
       "<!-- save_to -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>save_to</title>\n",
       "<text text-anchor=\"middle\" x=\"699\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">save_to=</text>\n",
       "</g>\n",
       "<!-- save_to&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>save_to&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M665.71,-144.59C646.28,-135.01 621.56,-122.82 600.6,-112.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"602.08,-109.32 591.57,-108.04 598.99,-115.6 602.08,-109.32\"/>\n",
       "</g>\n",
       "<!-- fill_template_&#45;&gt;fill_template -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>fill_template_&#45;&gt;fill_template</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557,-71.7C557,-63.98 557,-54.71 557,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"560.5,-46.1 557,-36.1 553.5,-46.1 560.5,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa41d01f280>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smart_cv import cv_content, fill_template, cv_text, _mk_parser\n",
    "from meshed import DAG\n",
    "from smart_cv.base import mall\n",
    "\n",
    "print(\"Avaible CVs in the app: \",list(mall.cvs))\n",
    "funcs = [#_mk_parser, \n",
    "         fill_template, \n",
    "         cv_text, \n",
    "         cv_content\n",
    "        ]\n",
    "dag1 = DAG(funcs)\n",
    "\n",
    "dag1.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"704pt\" height=\"908pt\"\n",
       " viewBox=\"0.00 0.00 704.43 908.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 904)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-904 700.43,-904 700.43,4 -4,4\"/>\n",
       "<!-- cv_text -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>cv_text</title>\n",
       "<text text-anchor=\"middle\" x=\"132.43\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text</text>\n",
       "</g>\n",
       "<!-- _mk_parser -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>_mk_parser</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"271.93,-684 190.93,-684 190.93,-648 271.93,-648 271.93,-684\"/>\n",
       "<text text-anchor=\"middle\" x=\"231.43\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">_mk_parser</text>\n",
       "</g>\n",
       "<!-- cv_text&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>cv_text&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.65,-719.88C169.36,-710.89 185.1,-699.76 198.86,-690.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.98,-692.82 207.12,-684.19 196.94,-687.11 200.98,-692.82\"/>\n",
       "</g>\n",
       "<!-- translate_content -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>translate_content</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"335.93,-252 226.93,-252 226.93,-216 335.93,-216 335.93,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.43\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">translate_content</text>\n",
       "</g>\n",
       "<!-- cv_text&#45;&gt;translate_content -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>cv_text&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.22,-722.43C65.99,-700.42 2.43,-654.83 2.43,-595 2.43,-595 2.43,-595 2.43,-377 2.43,-336.55 -7.3,-316.47 21.43,-288 48.44,-261.25 148.67,-246.96 216.5,-240.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.06,-243.65 226.67,-239.2 216.38,-236.68 217.06,-243.65\"/>\n",
       "</g>\n",
       "<!-- cv_name -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>cv_name</title>\n",
       "<text text-anchor=\"middle\" x=\"301.43\" y=\"-878.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_name</text>\n",
       "</g>\n",
       "<!-- cv_text_ -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>cv_text_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"302.93,-828 239.93,-828 239.93,-792 302.93,-792 302.93,-828\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.43\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">cv_text_</text>\n",
       "</g>\n",
       "<!-- cv_name&#45;&gt;cv_text_ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>cv_name&#45;&gt;cv_text_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.02,-863.7C290.64,-855.81 286.56,-846.3 282.81,-837.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285.92,-835.92 278.76,-828.1 279.49,-838.67 285.92,-835.92\"/>\n",
       "</g>\n",
       "<!-- fill_template_ -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>fill_template_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"551.93,-108 458.93,-108 458.93,-72 551.93,-72 551.93,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"505.43\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">fill_template_</text>\n",
       "</g>\n",
       "<!-- cv_name&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>cv_name&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M334.63,-871.62C386.88,-854.59 482.43,-813.29 482.43,-739 482.43,-739 482.43,-739 482.43,-233 482.43,-192.7 491.57,-146.78 498.33,-118.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"501.8,-118.89 500.78,-108.34 495,-117.22 501.8,-118.89\"/>\n",
       "</g>\n",
       "<!-- cv_text_&#45;&gt;cv_text -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>cv_text_&#45;&gt;cv_text</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.89,-793.12C219.01,-782.6 191.52,-768.76 169.58,-757.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.05,-754.53 160.55,-753.16 167.91,-760.78 171.05,-754.53\"/>\n",
       "</g>\n",
       "<!-- raw_dict_content -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>raw_dict_content</title>\n",
       "<text text-anchor=\"middle\" x=\"231.43\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">raw_dict_content</text>\n",
       "</g>\n",
       "<!-- has_content_labelling -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>has_content_labelling</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"291.93,-540 156.93,-540 156.93,-504 291.93,-504 291.93,-540\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.43\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">has_content_labelling</text>\n",
       "</g>\n",
       "<!-- raw_dict_content&#45;&gt;has_content_labelling -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>raw_dict_content&#45;&gt;has_content_labelling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.7,-575.7C228.93,-567.98 228,-558.71 227.14,-550.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.62,-549.71 226.14,-540.1 223.66,-550.4 230.62,-549.71\"/>\n",
       "</g>\n",
       "<!-- chunk_overlap -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>chunk_overlap</title>\n",
       "<text text-anchor=\"middle\" x=\"231.43\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">chunk_overlap=</text>\n",
       "</g>\n",
       "<!-- chunk_overlap&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>chunk_overlap&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.43,-719.7C231.43,-711.98 231.43,-702.71 231.43,-694.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.93,-694.1 231.43,-684.1 227.93,-694.1 234.93,-694.1\"/>\n",
       "</g>\n",
       "<!-- temperature -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>temperature</title>\n",
       "<text text-anchor=\"middle\" x=\"347.43\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">temperature=</text>\n",
       "</g>\n",
       "<!-- temperature&#45;&gt;_mk_parser -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>temperature&#45;&gt;_mk_parser</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.06,-719.88C303.89,-710.72 285.03,-699.34 268.69,-689.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"270.29,-686.36 259.92,-684.19 266.67,-692.35 270.29,-686.36\"/>\n",
       "</g>\n",
       "<!-- _mk_parser&#45;&gt;raw_dict_content -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>_mk_parser&#45;&gt;raw_dict_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.43,-647.7C231.43,-639.98 231.43,-630.71 231.43,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.93,-622.1 231.43,-612.1 227.93,-622.1 234.93,-622.1\"/>\n",
       "</g>\n",
       "<!-- labeled_optional_content -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>labeled_optional_content</title>\n",
       "<text text-anchor=\"middle\" x=\"224.43\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">labeled_optional_content</text>\n",
       "</g>\n",
       "<!-- label_empty_content -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>label_empty_content</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"167.93,-396 36.93,-396 36.93,-360 167.93,-360 167.93,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.43\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">label_empty_content</text>\n",
       "</g>\n",
       "<!-- labeled_optional_content&#45;&gt;label_empty_content -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>labeled_optional_content&#45;&gt;label_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.59,-431.88C178.49,-422.64 158.43,-411.13 141.14,-401.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.81,-398.13 132.39,-396.19 139.32,-404.2 142.81,-398.13\"/>\n",
       "</g>\n",
       "<!-- optional_content -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>optional_content</title>\n",
       "<text text-anchor=\"middle\" x=\"100.43\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">optional_content=</text>\n",
       "</g>\n",
       "<!-- optional_content&#45;&gt;has_content_labelling -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>optional_content&#45;&gt;has_content_labelling</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.77,-575.88C147.13,-566.64 167.52,-555.13 185.09,-545.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.99,-548.15 193.98,-540.19 183.55,-542.06 186.99,-548.15\"/>\n",
       "</g>\n",
       "<!-- has_content_labelling&#45;&gt;labeled_optional_content -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>has_content_labelling&#45;&gt;labeled_optional_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.43,-503.7C224.43,-495.98 224.43,-486.71 224.43,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.93,-478.1 224.43,-468.1 220.93,-478.1 227.93,-478.1\"/>\n",
       "</g>\n",
       "<!-- labeled_empty_content -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>labeled_empty_content</title>\n",
       "<text text-anchor=\"middle\" x=\"102.43\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">labeled_empty_content</text>\n",
       "</g>\n",
       "<!-- labeled_empty_content&#45;&gt;translate_content -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>labeled_empty_content&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.22,-287.88C171.02,-278.18 202.21,-265.98 228.39,-255.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.75,-258.97 237.79,-252.07 227.2,-252.45 229.75,-258.97\"/>\n",
       "</g>\n",
       "<!-- empty_label -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>empty_label</title>\n",
       "<text text-anchor=\"middle\" x=\"83.43\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">empty_label=</text>\n",
       "</g>\n",
       "<!-- empty_label&#45;&gt;label_empty_content -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>empty_label&#45;&gt;label_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M88.13,-431.7C90.25,-423.9 92.79,-414.51 95.15,-405.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.55,-406.67 97.79,-396.1 91.79,-404.84 98.55,-406.67\"/>\n",
       "</g>\n",
       "<!-- label_empty_content&#45;&gt;labeled_empty_content -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>label_empty_content&#45;&gt;labeled_empty_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.43,-359.7C102.43,-351.98 102.43,-342.71 102.43,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.93,-334.1 102.43,-324.1 98.93,-334.1 105.93,-334.1\"/>\n",
       "</g>\n",
       "<!-- translated_dict_content -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>translated_dict_content</title>\n",
       "<text text-anchor=\"middle\" x=\"359.43\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">translated_dict_content</text>\n",
       "</g>\n",
       "<!-- translated_dict_content&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>translated_dict_content&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M395.15,-143.88C414.93,-134.39 439.71,-122.51 460.76,-112.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.33,-115.55 469.83,-108.07 459.3,-109.24 462.33,-115.55\"/>\n",
       "</g>\n",
       "<!-- bytes_content_ -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>bytes_content_</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"408.43,-108 310.43,-108 310.43,-72 408.43,-72 408.43,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"359.43\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">bytes_content_</text>\n",
       "</g>\n",
       "<!-- translated_dict_content&#45;&gt;bytes_content_ -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>translated_dict_content&#45;&gt;bytes_content_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.43,-143.7C359.43,-135.98 359.43,-126.71 359.43,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.93,-118.1 359.43,-108.1 355.93,-118.1 362.93,-118.1\"/>\n",
       "</g>\n",
       "<!-- language -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>language</title>\n",
       "<text text-anchor=\"middle\" x=\"229.43\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">language=</text>\n",
       "</g>\n",
       "<!-- language&#45;&gt;translate_content -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>language&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M242.29,-287.7C248.46,-279.39 255.97,-269.28 262.76,-260.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"265.57,-262.22 268.73,-252.1 259.95,-258.04 265.57,-262.22\"/>\n",
       "</g>\n",
       "<!-- language_list -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>language_list</title>\n",
       "<text text-anchor=\"middle\" x=\"333.43\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">language_list=</text>\n",
       "</g>\n",
       "<!-- language_list&#45;&gt;translate_content -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>language_list&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.58,-287.7C314.41,-279.39 306.9,-269.28 300.11,-260.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"302.91,-258.04 294.14,-252.1 297.29,-262.22 302.91,-258.04\"/>\n",
       "</g>\n",
       "<!-- chat -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>chat</title>\n",
       "<text text-anchor=\"middle\" x=\"427.43\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">chat=</text>\n",
       "</g>\n",
       "<!-- chat&#45;&gt;translate_content -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>chat&#45;&gt;translate_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M400.31,-292C379.47,-282.01 350.24,-267.99 325.98,-256.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.49,-253.2 316.96,-252.03 324.46,-259.51 327.49,-253.2\"/>\n",
       "</g>\n",
       "<!-- translate_content&#45;&gt;translated_dict_content -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>translate_content&#45;&gt;translated_dict_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M300.71,-215.7C310.35,-207.05 322.16,-196.45 332.66,-187.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"335.27,-189.39 340.37,-180.1 330.59,-184.18 335.27,-189.39\"/>\n",
       "</g>\n",
       "<!-- fill_template -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>fill_template</title>\n",
       "<text text-anchor=\"middle\" x=\"505.43\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">fill_template</text>\n",
       "</g>\n",
       "<!-- template_path -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>template_path</title>\n",
       "<text text-anchor=\"middle\" x=\"561.43\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">template_path=</text>\n",
       "</g>\n",
       "<!-- template_path&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>template_path&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M547.59,-143.7C540.94,-135.39 532.85,-125.28 525.55,-116.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"528.1,-113.73 519.12,-108.1 522.63,-118.1 528.1,-113.73\"/>\n",
       "</g>\n",
       "<!-- save_to -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>save_to</title>\n",
       "<text text-anchor=\"middle\" x=\"663.43\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">save_to=</text>\n",
       "</g>\n",
       "<!-- save_to&#45;&gt;fill_template_ -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>save_to&#45;&gt;fill_template_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M630.31,-146.33C608,-136.44 578.23,-123.25 553.35,-112.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"554.64,-108.97 544.08,-108.12 551.8,-115.37 554.64,-108.97\"/>\n",
       "</g>\n",
       "<!-- fill_template_&#45;&gt;fill_template -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>fill_template_&#45;&gt;fill_template</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M505.43,-71.7C505.43,-63.98 505.43,-54.71 505.43,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"508.93,-46.1 505.43,-36.1 501.93,-46.1 508.93,-46.1\"/>\n",
       "</g>\n",
       "<!-- bytes_content -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>bytes_content</title>\n",
       "<text text-anchor=\"middle\" x=\"359.43\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">bytes_content</text>\n",
       "</g>\n",
       "<!-- bytes_content_&#45;&gt;bytes_content -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>bytes_content_&#45;&gt;bytes_content</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.43,-71.7C359.43,-63.98 359.43,-54.71 359.43,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.93,-46.1 359.43,-36.1 355.93,-46.1 362.93,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa41cfe0460>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smart_cv import dag_pipeline\n",
    "\n",
    "dag_pipeline.dot_digraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SCH\\nSenior DevSecOps Engineer\\n8 years exp\\nAvailable immediately – End of trial\\nperiode 28/03\\nWork-Experience:\\nLead DevOps:\\nsince may 2023\\nMission [3]: Deploy Drupal & Wordpress websites with SFTP & SMTP services on K8S (kapsule)\\nTools: scaleway, kapsule, container registry, vpc, public gateway, Loadbalancers, block storage, object storage,\\nbitbucket, gitlabci, helm-chart, terraform, Kubernetes, docker, docker-compose, let’s encrypt, cert-manager, nginx\\nTasks/Responsibilities:\\n- IaC creation using terraform template,\\n- PaC creation using gitlab.ci to deploy the IaC on Scaleway cloud provider\\n- PaC creation to build & deploy the websites using bitbucket\\n- website helm chart creation\\n- git branching & versioning\\nMission [2]: Build SIEM Stack\\nTools: scaleway, kapsule, container registry, serverless functions, serverless jobs, vpc, public gateway, external\\nDNS, Loadbalancers, block storage, object storage, gitlabci, helm-chart, terraform, Kubernetes, docker, docker-\\ncompose, let’s encrypt, cert-manager, nginx\\nTasks/Responsibilities:\\n- IaC creation using terraform template,\\n- PaC creation using gitlab.ci to deploy the IaC on Scaleway cloud provider\\n- Wazuh Cluster creation as K8S workloads\\n- Graylog deployment & link with wazuh cluster\\nMission [1]: migrate banking solution from VMs to openshift cluster (OCP)\\nTools: azure DevOps, harbor, artifactory, openshift, vsphere\\nTasks/Responsibilities:\\n- Develop CICD pipelines using Azure DevOps,\\n- install openshift infrastructure on prem using vsphere\\n- migrate application from VMs to openshift cluster\\nSenior DevOps Engineer & Team Lead: [Keyrus MEA]\\nNov. 2022 - April 2023\\nProject: Samea (MaxIt) SuperApp: a telco Mobile & web application for Orange MEA (hosted in 8\\ncountries to be used by most than 80K users), mainly composed of 6 modules each one holds at least\\n10 micro-services, deployed on Private Cloud based on Openstack & openshift.\\n--------------\\nTools: Openshift, Kubernetes, Helm, Docker, docker-compose, github Actions, SonarQube, Harbor,\\nRedhat GitOps (ArgoCD), Prometheus, Grafana, Loki, ELK, S3, MinIO, SDN, Kafka, mongoDB,\\npostgreSql, Keycloak, Krakend, killbill, Openstack, Linux/ubuntu Dependabot, Maven, quarkus,\\nnode.js, flutter, Swagger, postman\\nTasks/Responsibilities:\\n➔ Design & implement a High available & scaling infrastructure, define the hosting & the sizing\\n➔ Design & implement the delivery and deployment strategies (blue/green, canary\\ndeployments).\\n➔ Design & implement the different workflows (CICD pipelines, observability workflows\\n{monitoring, logging, tracing})\\n➔ Write the Architectural Design Documents (DAT, HLD, LLD)\\n➔ Accelerate & Secure the SDLC with DevSecOps Strategies (design & apply the needed\\npolicies, standards, controls & best practices)\\n◆ Git Branching, versioning & Release Management\\n◆ Secure coding using Dependabot, SCA, SAST, DAST, IAST\\n◆ Container & image Scan using Harbor (trivy/clair) to detect vulnerabilities. + Define &\\ncreate network policies, execute non-root containers, …\\n◆ API security: API Gateway configuration (krakend) & Oauth2 integration (keyclaok)\\nfor authentication & authorisation, CORS Configuration, mTLS usage,\\n◆ security & compliance: identity and Access management (RBAC) & policies\\nenforcement & Secrets management\\n➔ Implement Infrastructure as a code & deploy it on Openshift clusters\\n➔ Implement Pipeline as a code (PaC) & Apply GitOps Strategies\\n➔ ensure that all infrastructure solutions delivered meet functional and non-functional business\\nrequirements\\n➔ Disaster Recovery & Business Continuity Planning\\nDevOps Engineer: [Venari Security]\\ndecember 2021 - october 2022\\nProject: Encrypted Traffic Analysis (ETA) platform. Without decryption, the platform leverages artificial\\nintelligence, machine learning, and behavioural analytics, allowing organisations to better understand their\\nencrypted traffic attack surface by detecting abnormal behaviour and adhering to internal and regulatory\\ncompliance.\\nTools: Rancher, rke, Kubernetes, Helm Vagrant, Packer, Terraform Docker, docker-compose, GitLab,\\nGitlab.CI, SonarCloud Prometheus, Grafana, ELK, datadog, splunk, Keycloak, Kafka, Storm, cratedb, postgresql,\\nsbt, maven, gradle, python, java, kotlin, springboot linux/ubuntu/Debian/centos, jira, AWS: EKS, EC2 instances,\\nSecurity Group (SG), Network access Security List (NACL), ALB/ELB, IAM, AMI, RDS, elastic IP, VPC, S3, EBS,\\nroute 53, cloudwatch,...\\nTasks/Responsibilities:\\n- Create the EKS Clusters using Terraform Templates\\n- Create on-prem Kubernetes Clusters using Rancher & RKE\\n- Create the needed K8S yaml files for all ETA platform components\\n- Create Helm charts\\n- Using packer generate various virtual disk image {OVA, AMI, VMDK} of the customized OS.\\n- Implement git workflow strategy for git branching, artifact versioning and deployment on the different\\nEKS environments {dev, staging, pre-prod, prod} - Implement CI/CD pipelines using gitlab.ci that\\ncontains theses main stages:\\n+ Static code analysis using sonarcloud for java applications, pylint & flake8 for python applications\\n+ Run unit tests, & integration tests\\n+ Build the artifact, then store it into GitLab package registry\\n--------------\\n+ Build docker image based on the artifact, then push it to the GitLab container registry\\n+ Deploy the new docker image on the different k8s clusters\\n- Apache Storm & Kafka & Cratedb Configuration - API Gateway Configuration\\nCloud & DevOps Software Designer: [Actia Engineering Services]\\napril 2020 - November 2021\\nProject: Migration of the diagbox desktop vehicle diagnostics app to cloud, for Stellantis (PSA)\\nTools: Rancher, RKE, Terraform, vagrant, Kubernetes, helm, kustomize, Docker, docker-compose, Git, SVN,\\nHudson, GoCD, sonarqube Artifactory, Harbor - Maven, Gradle, Java/springboot, Perl, GoLang, Keycloak,\\nWindows, Linux/ubuntu/Alpine, Jira, Azure: AKS, ACR, Application Gateway, - AGIC, IAM, Storage Account,\\nDNS, Vault, VNet/Subnet, Blob Storage, VPN - Gateway\\nTasks/Responsibilities:\\n- Create Azure Environments (dev, qa, wdb) for the deployment of DiagCloud project, this environment is\\ncomposed of a resource group that include a VNet/subnet, AKS cluster, ACR, AG, managed identity,\\nstorage account, vault key. And create DNS Zones & Make the deployment of DiagCloud project in all\\nthese environments.\\n- Create AKS Cluster containing Linux & Windows Server nodes, to be able to deploy ASP.net application\\n& Java microservices & C++ applications as containers\\n- Create the different K8S yaml files, that are necessaries for the deployment of DiagCloud project.\\n- Implement the HPA scaling system based on gathered metrics on Prometheus, for a set of\\nmicroservices deployed in AKS clusters Use Kustomize to update configuration options according to our\\nenvironments (dev, qa, prod)\\n- Create/update springboot and angular projects files configuration to manage all profiles\\n- Dockerization of Spring boot & Angular Projects using multi-stage build\\n- Dockerfiles & extracted jar layer\\n- Static code analysis using PMD, checkstyle, FixBugs, ...\\n- Build maven projects usingHudson & upload them to artifactory\\n- Build CICD pipeline using Hudson & GoCD\\n- Store & Scan Docker images for vulnerabilities using Clair/harbor\\nArtificial Intelligence & Robotic Process Automation Engineer: [Tessi]\\nJan. 2019 – Apr. 2020\\nProject: Implementation of Several Supervised Machines Learning Models that make information extraction,\\ndocuments classification & clustering for the account of HSBC, Malakoff Médéric & Pole Emploi, based on\\nMLOps strategies & pipelines.\\nTools: Mesos, docker, docker-compose, podman, Workfusion RPA Express, Workfusion studio v9.0, control\\ntower, workspace, json, SOAP, REST, AutoML, Selenium, Sikuli, Groovy, java, python, Jira.\\nTasks/Responsibilities:\\n- Create MLOps pipelines\\n- Create dockerfile, podman containers, & deploy it into Mesos\\n- Defines, designs, develops, configures, tests, maintains, and supports cognitive automation process\\nsolutions to meet business objectives using machine learning models & techniques.\\n- Create reusable automation framework and libraries\\n- Analyze issues and new business needs to provide optimized solutions.\\n- Unit test applications to verify compliance with specifications and support system testing.\\n- Provide production system support,investigating/addressing issues.\\n- Report status regularly to management.\\nContinuous Integration & Quality Analyst Engineer: [IP-Label]\\nJun. 2018 – Jan. 2019\\n--------------\\nProject: Implement Continuous integration pipelines & test automation for mobile & web application {newtest,\\ndragonfly, datametrie}, these applications assess the QoE, the Quality of User Experience\\nTools: docker, docker-compose, Jenkins, sonarqube, Java, Python, Selenium, Cucumber, Sikuli, TestNG, Junit,\\nSoapUI, Appium, HttpWatch, Fiddler, HARAnalyzer, EasyVista, Git, SVN, TestLink, windows server 2012R2,\\nLinux, DataMetrie, NewTest, VMware, Esxi, Xen.\\nTasks/Responsibilities:\\n- implement continuous integration pipelines using jenkins\\n- check code quality using sonarqube\\n- simulate prod environment by implementing dockerfile, running docker images using docker-\\ncompose\\n- test mobile, web & desktop applications\\n- test servers and platforms configuration\\n- Create test plans, tests automation, manage test execution, record test progress and results,\\nanalyze tests results, document test cases.\\n- identify, isolate, and track bugs, identify potential problems that users may encounter.\\n- The use of cloud machines on OVH & AWS to make tests, install & update the test\\nenvironments.\\n- Work effectively and collaboratively with R&D and Support teams\\nComputer Science Teaching Assistant: [TBS, UTC, Collège LaSalle]\\nJan. 2015 – Jun 2018\\n- Web development - Information System - Operating System\\n- POO/Java\\n- DB/Oracle\\nEducation:\\n2013 - 2015 Master Business Intelligence\\nThe Higher Institute of Management of Tunis (ISG)\\n2010 - 2013 Information Technology Management Diploma\\nThe Higher Institute of Management of Tunis (ISG)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.cvs['SCH.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The json is not well formatted. Trying again...\n",
      "Language detected: french\n",
      "Language detected: french\n"
     ]
    }
   ],
   "source": [
    "content = dag2('Guillaume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quentin ROMAN\\nLooking for a Job in Software Development\\nNewly Graduated Software Engineer, Team Worker, Motivated and\\nPassionate with new Technologies.\\n\\uf0e0quentin.roman7@gmail.com \\uf041 Cannes, Sophia-Antipolis, Nice\\n\\uf073 23 years old \\uf098 +33 6 51 20 20 82\\nLANGUAGES\\nEDUCATION\\nFrench\\nEngineering Degree in Computer Science\\nEnglish\\nCESI - Nice - From 2018 to 2023\\n› TOEIC : 975/990\\nAcademic Background\\n• Network Administration • Cyber Security\\nPERSONNAL\\n• Software Development • Web Development\\nPROJECTS\\n• Database Management • Data Analysis\\n• Project Planning • Git Management\\nExperimenting VR\\nApplications\\nWORK EXPERIENCE\\n(C# / Unity)\\nWeb Development\\nModel Training for\\nMachine Learning Amadeus - Sophia Antipolis - From September 2022 to September 2023\\nexperimentation with a Developed Web-based Angular Application for Hospitality IT business\\nsmall Dataset Enhanced internal Diagnostic tools with new features to improve user\\n(Python / Jupyter experience\\nNotebook) Implemented a secure permissions system for managing user data access\\nCollaborated within an Agile development environment (SCRUM)\\nData Backup and Investigated and resolved production issues through Problem Trouble\\nEncryption Software Report (PTR)\\n(C# / WPF / MVVM)\\nSoftware Development\\nSKILLS Aalborg University - Denmark - From September 2021 to February 2022\\nDeveloped a VR application for medical purposes, aiding in the recovery of\\nLanguages stroke patients.\\nJavascript, C#, Java, Conducted testing sessions involving students and patients to gather\\nPython, PHP, C++, C feedback and refine the application.\\nOptimized code and implemented multi-threading techniques for\\nFramework enhanced performance.\\nAngular, Node, Laravel, Analyzed eye-tracking data for user interaction insights.\\nReact, Spring, Express,\\n.NET Network Administration\\nTournaire - Grasse, France - From January 2021 to June 2021\\nCommon\\nAdministered network systems, including hardware configuration and\\nVirtualization, Docker, Git,\\ninstallation.\\nMongoDB, Linux, Virtual\\nImplemented a Multi-Factor Authenticator for Cisco VPN.\\nReality, SQL, Data Science\\nInstalled a Centralized Log Solution with Elasticsearch for efficient log\\nmanagement.\\nSoft\\nManaged and maintained Virtual Machines using VMware vSphere.\\nProblem-Solving,\\nTroubleshooted network and system issues.\\nAdaptability, Attention to\\nDetail, Self-Motivation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.cvs['quentin.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from meshed import DAG\n",
    "from oa import prompt_function, chat\n",
    "from functools import partial\n",
    "template = \"I will give you a text extracted from a pdf but with errors like unwated spaces or special characters. You will have to clean it and return the cleaned text. Here is the text: \\n\\n{content}\\n\\nPlease clean it and return the cleaned text.\"\n",
    "my_chat = partial(chat, temperature=0)\n",
    "f = prompt_function(template, prompt_func=my_chat)\n",
    "\n",
    "def concat_json_text(d:dict)->str:\n",
    "    text = \"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            text += concat_json_text(value)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    text += concat_json_text(item)\n",
    "                else:\n",
    "                    text += str(item) + \", \"\n",
    "        else:\n",
    "            text +=  str(value) + \", \"\n",
    "    return f(content=text)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def text(concat_json_text:str)->str:\n",
    "    return concat_json_text\n",
    "\n",
    "\n",
    "def lemmentizer(text:str)->list[str]:\n",
    "    # Tokenisation des mots dans le texte\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Initialisation du lemmatiseur WordNet\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Récupération des mots vides (stop words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Ponctuations à ignorer\n",
    "    punkt = {'.', ',', ';', '!', '?', ':', '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '-', '_', '+', '=', '*', '&', '^', '%', '$', '#', '@', '~', '`', \"'\", '\"'}\n",
    "    \n",
    "    # Lemmatisation des mots en ignorant les mots vides\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.lower() not in stop_words and word not in punkt]\n",
    "    \n",
    "    return lemmatized_words\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# text = \"I am a developer and I am Working on a project TO develop a NEW application !&&\"\n",
    "# lemmas = lemmentizer(text)\n",
    "# print(lemmas)\n",
    "\n",
    "def symetric_difference(text1, text2):\n",
    "    return set(lemmentizer(text1)).symmetric_difference(set(lemmentizer(text2)))\n",
    "\n",
    "def intersection(text1, text2):\n",
    "    if isinstance(text1, str):\n",
    "        set1 = set(lemmentizer(text1))\n",
    "    else:\n",
    "        set1 = text1\n",
    "    if isinstance(text2, str):\n",
    "        set2 = set(lemmentizer(text2))\n",
    "    else:\n",
    "        set2 = text2\n",
    "    return set1.intersection(set2)\n",
    "\n",
    "def missing_words(original_text:str, copy:str)->set:\n",
    "    return set(lemmentizer(original_text)).difference(set(lemmentizer(copy)))\n",
    "\n",
    "# text1 = \"Rédaction de rapports\"\n",
    "# text2 = \"lecture des rapports\"\n",
    "\n",
    "# symetric_difference(text1, text2)\n",
    "# print(intersection(text1, text2))\n",
    "# print(missing_words(text1, text2))\n",
    "\n",
    "def missed_content(original_text:str, json_content:dict):\n",
    "    json_text = concat_json_text(json_content)\n",
    "    return symetric_difference(original_text, json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = missed_content(mall.cvs['quentin.pdf'], content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'French\\nEnglish\\n› TOEIC : 975/990\\nExperimen ting VR\\nApplica tions\\n(C# / U nity)\\nModel Training f or\\nMachine L earning\\nexperimen tation with a\\nsmall D atase t\\n(Python / Jupyter\\nNotebook)\\nData Backup and\\nEncryp tion S oftware\\n(C# / WPF  / MVVM)\\nLanguag es\\nJavascrip t, C#, Java,\\nPython, PHP , C++, C\\nFrame work\\nAngular , Node, Lar avel,\\nReact, S pring, Expr ess,\\n.NET\\nCommon\\nVirtualiza tion, D ocker, Git,\\nMongoDB, Linux, Virtual\\nReality , SQL, D ata Scienc e\\nSoft\\nProblem-S olving,\\nAdaptability , Attention t o\\nDetail, S elf-MotivationQuentin ROMAN\\nLooking f or a Job in S oftware Developmen t\\nNewly Gradua ted Software Engineer , Team Worker, Motivated and\\nPassiona te with ne w Technolo gies.\\nEngineering D egree in C omput er Scienc e\\nCESI  Nice From 2018  to 2023\\nAcademic B ackgr ound\\n• Network Administr ation        • Cyber  Security\\n• Software Developmen t           • Web D evelopmen t\\n• Database M anag emen t             • Data Analysis\\n• Project P lanning                                      • Git Manag emen t\\nWeb D evelopmen t\\nAmadeus  Sophia Antipolis  From September  2022  to September  2023\\nDeveloped Web-based Angular  Applica tion f or Hospitality  IT business\\nEnhanc ed in ternal D iagnostic t ools with ne w features to impr ove user\\nexperienc e\\nImplemen ted a secur e permissions s ystem f or managing user  data ac cess\\nCollabor ated within an Agile de velopmen t environmen t (SCR UM)\\nInvestiga ted and r esolv ed pr oduction issues thr ough P roblem Trouble\\nReport (PTR)\\nSoftware Developmen t\\nAalbor g University Denmark  From September  2021  to February  2022\\nDeveloped a VR applica tion f or medical purposes, aiding in the r ecovery of\\nstroke pa tients.\\nConduct ed testing sessions in volving studen ts and pa tients to gather\\nfeedback and r eﬁne the applica tion.\\nOptimiz ed code and implemen ted multi-thr eading t echniques f or\\nenhanc ed perf ormanc e.\\nAnalyz ed eye-tracking da ta for user  interaction insigh ts.\\nNetwork Administr ation\\nTournair e Grasse, F rance From January  2021  to June 2021\\nAdminist ered ne twork s ystems, including har dware conﬁgur ation and\\ninstalla tion.\\nImplemen ted a M ulti-F actor Authen ticator for Cisc o VPN.\\nInstalled a C entralized Log Solution with E lasticsear ch for eﬃcien t log\\nmanag emen t.\\nManag ed and main tained Virtual M achines using VMware vSpher e.\\nTroubleshoo ted ne twork and s ystem issues.quen tin.roman7@gmail.c om \\uf0e0\\n 23 y ears old \\uf073 Cannes, Sophia-A ntipolis, Nice \\uf041\\n +33 6 51 20 20 82 \\uf098\\n- - \\n- - \\n- - \\n- - LANGUAGES\\nPERSONNAL\\nPROJECTS\\nSKILLSEDUCATION\\nWORK EXPERIENCE'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mall.cvs['quentin.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FullName': 'Guillaume Bernard',\n",
       " 'JobTitle': 'Ingénieur Backend Junior',\n",
       " 'avaibility': 'dès aujourd’hui',\n",
       " 'mobility': 'Missing information',\n",
       " 'seniority': 'Missing information',\n",
       " 'skills': 'Python, Java, Docker, Bash',\n",
       " 'certifications': 'Certificat en Anglais Avancé (C1)',\n",
       " 'experiences': [{'title': 'Ingénieur Backend Junior',\n",
       "   'company': 'Beewey Consulting',\n",
       "   'dates': '2023 - 3 mois',\n",
       "   'description': 'Migration de données, développement cloud, microservices, API',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'C, JSON, Flask, Terraform, VSCode'},\n",
       "  {'title': 'Ingénieur Fiabilité de Site',\n",
       "   'company': 'Thales DIS',\n",
       "   'dates': '2022 - 1 an',\n",
       "   'description': 'Service de gestion des incidents',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'},\n",
       "  {'title': 'Maitre-Nageur',\n",
       "   'company': 'Aqualand, Parc Aquatique',\n",
       "   'dates': '2020',\n",
       "   'description': 'Surveillant de baignade',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'}],\n",
       " 'personal_projects': 'Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC',\n",
       " 'languages': 'Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)',\n",
       " 'education': [{'diploma': 'Master en Big Data, Cloud Computing, Développement Logiciel',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2020-2022'},\n",
       "  {'diploma': 'Licence en Sciences Informatiques & Electronique',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2017-2020'},\n",
       "  {'diploma': 'Baccalauréat Scientifique – Mention Bien',\n",
       "   'school': 'Lycée Jean Moulin',\n",
       "   'dates': '2014-2017'}],\n",
       " 'interests': 'Data au sens large, Data Mining, Statistiques, Apprentissage Automatique, Arts Martiaux',\n",
       " 'has_certifications': True,\n",
       " 'has_personal_projects': True,\n",
       " 'has_interests': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from oa.base import chat\n",
    "my_chat = partial(chat, model=\"gpt-4\")\n",
    "f = prompt_function(template, prompt_func=my_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content retrieved:  {'FullName': 'Quentin Roman', 'JobTitle': 'Software Engineer', 'avaibility': 'Immediately', 'mobility': 'none', 'seniority': 'Newly Graduated', 'skills': 'Python, C#, Java, JavaScript, Angular, Node, React, .NET, SQL, Git, MongoDB, Linux, Virtual Reality', 'certifications': 'none', 'experiences': [{'title': 'Software Development', 'company': 'Aalborg University Denmark', 'dates': 'September 2021 - February 2022', 'description': 'Developed a VR application for medical purposes, aiding in the recovery of stroke patients.', 'tasks': ['Conducted testing sessions involving students and patients to gather feedback and refine the application', 'Optimized code and implemented multi-threading techniques for enhanced performance', 'Analyzed eye-tracking data for user interaction insights'], 'tools': 'Python, C#, VR technologies'}, {'title': 'Network Administration', 'company': 'Tournaire Grasse, France', 'dates': 'January 2021 - June 2021', 'description': 'Administered network systems, including hardware configuration and installation.', 'tasks': ['Implemented a Multi-Factor Authenticator for Cisco VPN', 'Installed a Centralized Log Solution with Elasticsearch for efficient log management', 'Managed and maintained Virtual Machines using VMware vSphere'], 'tools': 'Networking tools, Cisco VPN, VMware'}, {'title': 'Web Development', 'company': 'Amadeus Sophia Antipolis', 'dates': 'September 2022 - September 2023', 'description': 'Developed Web-based Angular Application for Hospitality IT business.', 'tasks': ['Enhanced internal diagnostic tools with new features to improve user experience', 'Implemented a secure permissions system for managing user data access'], 'tools': 'Angular, Web development technologies'}], 'personal_projects': 'none', 'languages': 'French, English', 'education': [{'diploma': 'Engineering Degree in Computer Science', 'school': 'CESI Nice', 'dates': '2018 - 2023'}], 'interests': 'Virtual Reality, Software Development, Networking, Web Development'}\n"
     ]
    }
   ],
   "source": [
    "keywords = mall.data['stacks_keywords.txt']\n",
    "\n",
    "original = f(mall.cvs['quentin.pdf'])\n",
    "\n",
    "retreived = concat_json_text(dag('quentin.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'september', 'optimized', 'science', 'involving', 'dataset', 'experimenting', 'grasse', 'engineer', 'technique', 'experience', '2018', 'backup', 'self-motivation', 'cisco', 'efficient', 'notebook', 'production', 'environment', 'angular', 'planning', 'recovery', 'performance', 'june', 'using', 'patient', 'web', 'purpose', 'aiding', 'model', 'newly', 'git', 'attention', 'centralized', 'encryption', 'skill', 'multi-factor', 'nice', 'soft', 'permission', 'january', 'refine', 'system', '975/990', 'medical', 'enhanced', 'authenticator', 'university', 'experimentation', 'investigated', 'tool', 'issue', 'virtual', 'administered', 'implemented', 'conducted', 'collaborated', 'maintained', 'student', 'application', 'virtualization', 'ptr', 'vsphere', 'vpn', 'gather', 'installation', 'jupyter', 'software', 'multi-threading', 'mongodb', 'session', 'tournaire', 'access', 'french', 'linux', 'problem', 'graduated', 'cesi', 'report', '20', 'motivated', 'trouble', 'computer', 'laravel', 'express', 'job', 'management', 'degree', 'february', 'installed', 'technology', 'business', 'engineering', 'troubleshooted', 'year', 'development', 'resolved', 'vr', 'passionate', 'hardware', 'quentin.roman7', '23', 'analysis', 'spring', 'sophia-antipolis', 'problem-solving', '51', 'agile', 'mvvm', 'academic', 'internal', 'within', 'including', 'training', 'sophia', 'analyzed', 'vmware', '6', 'developed', 'user', 'secure', 'managing', 'detail', 'amadeus', 'reality', 'stroke', 'framework', 'web-based', 'roman', '+33', 'scrum', 'unity', '.net', 'testing', 'configuration', 'insight', 'solution', 'small', 'antipolis', 'new', 'worker', 'feedback', 'code', 'administration', 'hospitality', 'france', 'elasticsearch', 'node', 'react', 'aalborg', 'javascript', 'toeic', 'looking', 'interaction', 'gmail.com', 'cannes', 'eye-tracking', '82', 'database', 'background', 'language', 'common', 'old', 'log', 'denmark', 'wpf', 'cyber', 'adaptability', 'english', 'c++', 'team', 'network', 'managed', 'improve', 'project', 'php', 'sql', 'quentin', '2021', 'diagnostic', 'feature', 'security'}\n",
      "{'project', 'sql', 'php', 'express', 'spring', 'agile', 'git', 'team', 'testing', '.net', 'management', 'scrum', 'react', 'javascript', 'angular', 'computer'}\n"
     ]
    }
   ],
   "source": [
    "retreived = concat_json_text(second_dict)\n",
    "missed = missing_words(original, retreived)\n",
    "missed_keywords = intersection(keywords, missed)\n",
    "print(missed)\n",
    "print(missed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_correction = \"\"\"I will give you a resume and some keywords you have to find in the resume. Then fill my json with the keywords\n",
    "Here is the resume: \\n\\n{resume}\\n\\nHere are the keywords: \\n\\n{keywords}\\n\\nHere is the json: \\n\\n{json}\\n\\nPlease fill the json with the keywords and preserve the json format with double quotes.\n",
    "Keep all the initial content of my json and add the missing keywords.\"\"\"\n",
    "\n",
    "second_fill = prompt_function(template_correction)\n",
    "\n",
    "second_json = second_fill(resume=original, keywords=missed_keywords, json=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"FullName\": \"Guillaume Bernard\",\\n    \"JobTitle\": \"Ingénieur Backend Junior\",\\n    \"avaibility\": \"dès aujourd’hui\",\\n    \"mobility\": \"Missing information\",\\n    \"seniority\": \"Missing information\",\\n    \"skills\": \"Python, Java, Docker, Bash\",\\n    \"certifications\": \"Certificat d\\'anglais avancé (C1)\",\\n    \"experiences\": [\\n        {\\n            \"title\": \"Ingénieur Backend Junior\",\\n            \"company\": \"Beewey Consulting\",\\n            \"dates\": \"2023 - 3 mois\",\\n            \"description\": \"Migration de données, développement cloud, microservices, API\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"C, JSON, Flask, Terraform, VSCode\"\\n        },\\n        {\\n            \"title\": \"Ingénieur Fiabilité de Site\",\\n            \"company\": \"Thales DIS\",\\n            \"dates\": \"2022 - 1 an\",\\n            \"description\": \"Service de gestion des incidents\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"Missing information\"\\n        },\\n        {\\n            \"title\": \"Maitre-Nageur\",\\n            \"company\": \"Aqualand, Parc Aquatique\",\\n            \"dates\": \"2020 - 3 mois\",\\n            \"description\": \"Surveillant de baignade\",\\n            \"tasks\": [\"Missing information\"],\\n            \"tools\": \"Missing information\"\\n        }\\n    ],\\n    \"personal_projects\": \"Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC\",\\n    \"languages\": \"Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)\",\\n    \"education\": [\\n        {\\n            \"diploma\": \"Master\",\\n            \"school\": \"ISEN Ecole d’Ingénieur\",\\n            \"dates\": \"2020 - 2022\"\\n        },\\n        {\\n            \"diploma\": \"Licence\",\\n            \"school\": \"ISEN Ecole d’Ingénieur\",\\n            \"dates\": \"2017 - 2020\"\\n        },\\n        {\\n            \"diploma\": \"Baccalauréat Scientifique\",\\n            \"school\": \"Lycée Jean Moulin\",\\n            \"dates\": \"2014 - 2017\"\\n        }\\n    ],\\n    \"interests\": \"Data au sens large, Data Mining, Statistiques, Machine Learning, Arts Martiaux\",\\n    \"has_certifications\": true,\\n    \"has_personal_projects\": true,\\n    \"has_interests\": true,\\n    \"keywords\": [\"php\", \"sql\", \"spring\", \"express\", \"git\", \"testing\", \".net\", \"react\", \"javascript\", \"angular\", \"computer\"]\\n}'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "second_dict = json.loads(second_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FullName': 'Guillaume Bernard',\n",
       " 'JobTitle': 'Ingénieur Backend Junior',\n",
       " 'avaibility': 'dès aujourd’hui',\n",
       " 'mobility': 'Missing information',\n",
       " 'seniority': 'Missing information',\n",
       " 'skills': 'Python, Java, Docker, Bash',\n",
       " 'certifications': \"Certificat d'anglais avancé (C1)\",\n",
       " 'experiences': [{'title': 'Ingénieur Backend Junior',\n",
       "   'company': 'Beewey Consulting',\n",
       "   'dates': '2023 - 3 mois',\n",
       "   'description': 'Migration de données, développement cloud, microservices, API',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'C, JSON, Flask, Terraform, VSCode'},\n",
       "  {'title': 'Ingénieur Fiabilité de Site',\n",
       "   'company': 'Thales DIS',\n",
       "   'dates': '2022 - 1 an',\n",
       "   'description': 'Service de gestion des incidents',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'},\n",
       "  {'title': 'Maitre-Nageur',\n",
       "   'company': 'Aqualand, Parc Aquatique',\n",
       "   'dates': '2020 - 3 mois',\n",
       "   'description': 'Surveillant de baignade',\n",
       "   'tasks': ['Missing information'],\n",
       "   'tools': 'Missing information'}],\n",
       " 'personal_projects': 'Reconnaissance Pomme & Poire - Entrainement modèle d’IA pour reconnaissance visuelle de variétés de fruits pour ARECO - ARFITEC',\n",
       " 'languages': 'Anglais (C1), Italien (Intermédiaire), Français (Natif), Hindi (Débutant)',\n",
       " 'education': [{'diploma': 'Master',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2020 - 2022'},\n",
       "  {'diploma': 'Licence',\n",
       "   'school': 'ISEN Ecole d’Ingénieur',\n",
       "   'dates': '2017 - 2020'},\n",
       "  {'diploma': 'Baccalauréat Scientifique',\n",
       "   'school': 'Lycée Jean Moulin',\n",
       "   'dates': '2014 - 2017'}],\n",
       " 'interests': 'Data au sens large, Data Mining, Statistiques, Machine Learning, Arts Martiaux',\n",
       " 'has_certifications': True,\n",
       " 'has_personal_projects': True,\n",
       " 'has_interests': True,\n",
       " 'project': True,\n",
       " 'agile': True,\n",
       " 'team': True,\n",
       " 'scrum': True,\n",
       " 'management': True}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_ai_request(reque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.33.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Using cached blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (1.24.0)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (2.2.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (8.2.3)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (4.9.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.18.0-cp39-cp39-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.0-cp39-cp39-macosx_10_12_x86_64.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.1/336.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: toolz, toml, smmap, rpds-py, mdurl, blinker, referencing, pydeck, markdown-it-py, gitdb, rich, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.3.0 blinker-1.7.0 gitdb-4.0.11 gitpython-3.1.43 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 pydeck-0.8.1b0 referencing-0.34.0 rich-13.7.1 rpds-py-0.18.0 smmap-5.0.1 streamlit-1.33.0 toml-0.10.2 toolz-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      👋 \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "      If you’d like to receive helpful onboarding emails, news, offers, promotions,\n",
      "      and the occasional swag, please enter your email address below. Otherwise,\n",
      "      leave this field blank.\n",
      "\n",
      "      \u001b[34mEmail: \u001b[0m ^C\n",
      "2024-04-08 14:50:52.599 \n"
     ]
    }
   ],
   "source": [
    "!streamlit run /Users/alexis/.conda/envs/rag/lib/python3.9/site-packages/ipykernel_launcher.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_cv import ContentRetriever\n",
    "import json \n",
    "keywords_text = \"\"\"Python, C,, Perl, Ruby, MatLab, Mathematica, Assembleur, VB, XML, Java, JEE, J2EE, JavaScript, PHP, R,, CSS, C\\+\\+, IOS, Swift, Android, Kotlin, Flutter, Dart, Rust, Ionic, Cordova, Reactnative, Xamarin, Babylon.js, C\\#, F\\#, WordPress, ThreeJS, WebGL,\n",
    "TensorFlow, Spark, Spring, Angular, Structs, Ember, Vue, Django, React, .NET,, .NET Core, Cocoapods, Osgi, Selenium, QA, Nest, Express, Symphony, Falcon, ASP.NET, WinDev, Flask, PySpark, Hibernate,\n",
    "Hive, Impala, Oracle, MySQL, Acess, SQL, SQL Server, PostgreSQL, Mongo, MariaDB, DBA,\n",
    "API, Unit Testing, Test Unitaire, Azure, Docker, Bamboo, Kubernetes, Jenkins, Jasmine, Karma, MVC, AWS,\n",
    "Git, Tortoise, TFS, CVS, SVN, MVC, GNU RCS, GNU CSSC, CVSNT, GNU arch, Darcs, DCVS, Monotone, Codeville, Mercurial, Bazaar, Fossil, Veracity, Pijul, SCCS, PVCS, Rational ClearCase, Harvest, CMVC, Visual SourceSafe, AccuRev SCM, Sourceanywhere, Team Foundation Server, Rational Synergy, Rational Team Concert, BitKeeper, Plastic SCM, IIS active directory, 2IS,\n",
    "Datawarehouse, Machine Learning, NLP, DeepLearning, Réseau de Neurones, kNN, k\\-NN, Régression Linéaire, SVM, Régression Logistique, Arbre de Décission, Fôrets Aléatoires, gradient boosting, PCA, Analyse en Composantes Principales, DataLake, DataFactory, PowerBI, Tableau, Qlikesense, GCP, OpenCV, Computer Vision, \n",
    "Gestion, Organization, Management, Agile, Scrum, Trello, JIRA, MS Project, Confluence, Sprint, GANTT, Specifications, Redaction, Cahier de charges, Workshop, Atelier, AMOA, PMO\"\"\"\n",
    "with open(\"prompt_dict.json\", \"r\") as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "def match_kewords(keywords_text, text):\n",
    "    \"\"\" Returns \"\"\"\n",
    "    keywords = keywords_text.split(\", \")\n",
    "    kw_list = []\n",
    "    for kw in keywords:\n",
    "        if kw in text:\n",
    "            if kw in [\"R,\", \"C,\"]:\n",
    "                continue\n",
    "            kw_list.append(kw)\n",
    "    for letter in [\"R\", \"C\"]:\n",
    "        for specials in [\" {letter}.\", \" {letter},\", \" {letter} \"]:\n",
    "            if specials in text:\n",
    "                kw_list.append(letter)\n",
    "    return kw_list\n",
    "\n",
    "def keywords_score(matched, pred):\n",
    "    pred = [kw.lower() for kw in pred]\n",
    "    score = 0\n",
    "    sames = []\n",
    "    missed = []\n",
    "    for kw in matched:\n",
    "        if kw.lower() in pred:\n",
    "            score += 1\n",
    "            sames.append(kw)\n",
    "        else:\n",
    "            missed.append(kw)\n",
    "    score = score / len(matched)\n",
    "    return score, sames, missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'Perl', 'Java', 'Selenium', 'Express', 'Azure', 'Docker', 'Kubernetes', 'Jenkins', 'SVN']\n"
     ]
    }
   ],
   "source": [
    "print(match_kewords(keywords_text, parser.dict_content[\"competences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match_kewords(keywords_text, parser.dict_content[\"competences\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guillaume.pdf', 'SCH.pdf', 'Adil.pdf', 'Nappee-Thomas.pdf', 'Thor_Whalen_CV.pdf']\n",
      "\n",
      "processing Guillaume.pdf\n",
      "matched: ['Python', 'Java', 'JavaScript', 'CSS', 'Spring', 'Flask', 'SQL', 'PostgreSQL', 'Docker', 'GCP']\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': {'message': 'Failed to create completion as the model generated invalid Unicode output. Unfortunately, this can happen in rare situations. Consider reviewing your prompt or reducing the temperature of your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_eccc43ef3a5318f641401cc799dbf0e4 in your message.)', 'type': 'server_error', 'param': None, 'code': 'invalid_model_output'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m matched \u001b[38;5;241m=\u001b[39m match_kewords(keywords_text, fullcontent)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatched: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatched\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m llm_keywords \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mdict_content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompetences\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_keywords: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_keywords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/smart_cv/smart_cv/ResumeParser.py:114\u001b[0m, in \u001b[0;36mContentRetriever.retrieve_content\u001b[0;34m(self, json_string, inplace, verbose)\u001b[0m\n\u001b[1;32m     49\u001b[0m     json_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts\n\u001b[1;32m     50\u001b[0m content_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124m        I will give you a resume and you will fill the provided json. \u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m        The keys have to be respected and the corresponding description will be replaced by the retrieved information.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124m        Gestion, Organization, Management, Agile, Scrum, Trello, JIRA, MS Project, Confluence, Sprint, GANTT, Specifications, Redaction, Cahier de charges, Workshop, Atelier, AMOA, PMO\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(content)\n",
      "File \u001b[0;32m~/Documents/GitHub/smart_cv/file_dialoger.py:74\u001b[0m, in \u001b[0;36mFile_Dialoger.ask_question\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_question\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain is not set. Please set it with build_chain method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion_variable\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/runnables/base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:166\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    163\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    165\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    175\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:544\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    543\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:438\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    433\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m }\n\u001b[0;32m--> 438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rag/lib/python3.9/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'error': {'message': 'Failed to create completion as the model generated invalid Unicode output. Unfortunately, this can happen in rare situations. Consider reviewing your prompt or reducing the temperature of your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID req_eccc43ef3a5318f641401cc799dbf0e4 in your message.)', 'type': 'server_error', 'param': None, 'code': 'invalid_model_output'}}"
     ]
    }
   ],
   "source": [
    "#get list of files in directory\n",
    "import os\n",
    "directory = \"../smart_cv/data/cvs\"\n",
    "files = os.listdir(directory)\n",
    "# remove .DS_Store file\n",
    "files.remove(\".DS_Store\")\n",
    "print(files)\n",
    "key = \"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\"\n",
    "avg_score = 0\n",
    "for cv_file in files:\n",
    "    print(f\"\\nprocessing {cv_file}\")\n",
    "    parser = ContentRetriever(cv_path=directory+\"/\"+cv_file, api_key=key,\n",
    "                    prompts=prompt_dict, chunk_size=20000, chunk_overlap=0, temperature=1.5, k=5)\n",
    "\n",
    "    fullcontent = \"\" \n",
    "    for doc in parser.documents:\n",
    "        fullcontent += doc.page_content\n",
    "\n",
    "    matched = match_kewords(keywords_text, fullcontent)\n",
    "    print(f\"matched: {matched}\")\n",
    "    parser.retrieve_content(verbose=False)\n",
    "\n",
    "    llm_keywords = parser.dict_content[\"competences\"].split(\", \")\n",
    "    print(f\"llm_keywords: {llm_keywords}\")\n",
    "    score, intersection, missed = keywords_score(matched, llm_keywords)\n",
    "    avg_score += score\n",
    "    print(f\"score: {score},\\n intersection: {intersection},\\n missed: {missed}\")\n",
    "\n",
    "avg_score = avg_score / len(files)\n",
    "print(f\"average score: {avg_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature=0 => avg score = 0.327\n",
    "Temperature=0.5 => avg score = 0.27\n",
    "Temperature=1 => avg score = 0.30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check content with instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "            \"Less than 11 bullet points for each experience\",\n",
    "            \"More than 3 bullet points for each experience\",\n",
    "            \"Framework versions have to be mentioned\",\n",
    "            \"Tasks done during experiences have to be mentioned\",\n",
    "            \"Context of the projects have to be mentioned: like dates, role, team size, company size, etc\",\n",
    "            \"Technical stacks have to be mentioned in experiences\",\n",
    "            \"There has to be contact information\",\n",
    "            \"If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_cv.CriteriaChecker import CriteriaChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CriteriaChecker(instructions, parser.dict_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Less than 11 bullet points for each experience': True,\n",
       " 'More than 3 bullet points for each experience': True,\n",
       " 'Framework versions have to be mentioned': True,\n",
       " 'Tasks done during experiences have to be mentioned': True,\n",
       " 'Context of the projects have to be mentioned: like dates, role, team size, company size, etc': True,\n",
       " 'Technical stacks have to be mentioned in experiences': True,\n",
       " 'There has to be contact information': True,\n",
       " 'If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.add_criterion(\"French or English language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Less than 11 bullet points for each experience': True,\n",
       " 'More than 3 bullet points for each experience': True,\n",
       " 'Framework versions have to be mentioned': True,\n",
       " 'Tasks done during experiences have to be mentioned': True,\n",
       " 'Context of the projects have to be mentioned: like dates, role, team size, company size, etc': True,\n",
       " 'Technical stacks have to be mentioned in experiences': True,\n",
       " 'There has to be contact information': True,\n",
       " 'If the profil is developer, there has to be a github link. Otherwise it is ok if there is no github link': True,\n",
       " 'French or English language': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.status  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcc\u001b[49m\u001b[38;5;241m.\u001b[39mfeedback()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "cc.feedback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
